{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up variables for constants such as absolute datapaths and the desired valdiation fraction split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnps\n",
    "datapath = \"G:\\\\Dev\\\\Data\\\\For Family\\\\GNPS Python Master\\\\Final Data.txt\"\n",
    "fingerprints_path = \"G:\\\\Dev\\\\Data\\\\For Family\\\\GNPS Python Master\\\\Final Fingerprints.txt\"\n",
    "fingerprints_names_path = \"G:\\\\Dev\\\\Data\\\\1000\\\\GNPS Python Master\\\\Fingerprint Legend.txt\"\n",
    "\n",
    "#gnps for family\n",
    "gnps_for_family_datapath = \"G:\\\\Dev\\\\Data\\\\For Family Q3\\\\GNPS Python Master\\\\Final Data.txt\"\n",
    "fingerprints_for_family_gnps_path = \"G:\\\\Dev\\\\Data\\\\For Family Q3\\\\GNPS Python Master\\\\Final Fingerprints.txt\"\n",
    "\n",
    "#mibig\n",
    "mibig_fingerprints_path = \"G:\\\\Dev\\\\Data\\\\Fingerprint Bitmaps 2\\\\mibig_unique_smiles.txt\"\n",
    "mibig_families_path = \"G:\\\\Dev\\\\Data\\\\Final Smiles Families.txt\"\n",
    "mibig_filtered_fingerprints_path = \"G:\\\\Dev\\\\Data\\\\Filtered Mibig GNPS Links\\\\Filtered Mibig Fingerprints.tsv\"\n",
    "mibig_filtered_families_path = \"G:\\\\Dev\\\\Data\\\\mibig_family.txt\"\n",
    "\n",
    "#npatlas\n",
    "npatlas_smiles_fingerprints_path = \"G:\\\\Dev\\\\Data\\\\Fingerprint Bitmaps 2\\\\NPAtlas_DB_last_version_filtered.txt\"\n",
    "npatlas_final_families_path = \"G:\\\\Dev\\\\Data\\\\NPAtlas_Final_Families.txt\"\n",
    "\n",
    "#test\n",
    "test_datapath = \"G:\\\\Dev\\\\Data\\\\For Family Test Q3\\\\GNPS Python Master\\\\Final Data.txt\"\n",
    "test_fingerprint_path = \"G:\\\\Dev\\\\Data\\\\For Family Test Q3\\\\GNPS Python Master\\\\Final Fingerprints.txt\"\n",
    "\n",
    "linked_fingerprints_path = \"G:\\\\Dev\\\\Data\\\\Linked GNPS Fingerprints.tsv\"\n",
    "families_names_path = \"G:\\\\Dev\\\\Data\\\\Family Legend.txt\"\n",
    "\n",
    "num_samples = 5770\n",
    "num_smiles_families_samples = 1368\n",
    "val_fraction = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import methods from ultilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_evaluation_interface import plot_loss, compute_auc, evaluate\n",
    "from nn_files_load_interface import *\n",
    "from nn_interface import simplified_fingerprint_model, simplified_family_model\n",
    "from nn_training_splits_interface import train_diff_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "spectra = load_master_file(path=datapath)\n",
    "fingerprints = load_fingerprints_master(path=fingerprints_path)\n",
    "\n",
    "gnps_spectra = load_master_file(path=gnps_for_family_datapath)\n",
    "gnps_fingerprints = load_fingerprints_master(path=fingerprints_for_family_gnps_path, number_of_rows=1)\n",
    "\n",
    "mibig_fingerprints = load_fingerprints_master(path=mibig_fingerprints_path)\n",
    "mibig_families = load_families_master(path=mibig_families_path)\n",
    "mibig_filtered_fingerprints = load_fingerprints_master(path=mibig_filtered_fingerprints_path, number_of_rows=1)\n",
    "mibig_filtered_families = load_families_master(path=mibig_filtered_families_path)\n",
    "\n",
    "fingerprint_names = load_fingerprint_legend(path=fingerprints_names_path)\n",
    "family_names = load_family_legend(path=families_names_path)\n",
    "\n",
    "test_spectra = load_master_file(path=test_datapath)\n",
    "test_fingerprint = load_fingerprints_master(path=test_fingerprint_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training/evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\nnpredict\\Code\\Python\\nn_interface.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  auto_model = Model(input=input_layer, output=out_layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5702 samples, validate on 634 samples\n",
      "Epoch 1/100\n",
      "5702/5702 [==============================] - 8s 1ms/step - loss: 0.5402 - val_loss: 0.3387\n",
      "Epoch 2/100\n",
      "5702/5702 [==============================] - 4s 668us/step - loss: 0.1931 - val_loss: 0.1636\n",
      "Epoch 3/100\n",
      "5702/5702 [==============================] - 4s 784us/step - loss: 0.1241 - val_loss: 0.1336\n",
      "Epoch 4/100\n",
      "5702/5702 [==============================] - 4s 702us/step - loss: 0.1122 - val_loss: 0.1227\n",
      "Epoch 5/100\n",
      "5702/5702 [==============================] - 4s 781us/step - loss: 0.1076 - val_loss: 0.1170\n",
      "Epoch 6/100\n",
      "5702/5702 [==============================] - 4s 757us/step - loss: 0.1051 - val_loss: 0.1135\n",
      "Epoch 7/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.1035 - val_loss: 0.1110\n",
      "Epoch 8/100\n",
      "5702/5702 [==============================] - 5s 913us/step - loss: 0.1022 - val_loss: 0.1092\n",
      "Epoch 9/100\n",
      "5702/5702 [==============================] - 5s 890us/step - loss: 0.1012 - val_loss: 0.1077\n",
      "Epoch 10/100\n",
      "5702/5702 [==============================] - 5s 863us/step - loss: 0.1004 - val_loss: 0.1065\n",
      "Epoch 11/100\n",
      "5702/5702 [==============================] - 5s 926us/step - loss: 0.0997 - val_loss: 0.1054\n",
      "Epoch 12/100\n",
      "5702/5702 [==============================] - 5s 888us/step - loss: 0.0990 - val_loss: 0.1045\n",
      "Epoch 13/100\n",
      "5702/5702 [==============================] - 5s 872us/step - loss: 0.0985 - val_loss: 0.1037\n",
      "Epoch 14/100\n",
      "5702/5702 [==============================] - 5s 804us/step - loss: 0.0979 - val_loss: 0.1030\n",
      "Epoch 15/100\n",
      "5702/5702 [==============================] - 4s 768us/step - loss: 0.0974 - val_loss: 0.1023\n",
      "Epoch 16/100\n",
      "5702/5702 [==============================] - 4s 784us/step - loss: 0.0969 - val_loss: 0.1017\n",
      "Epoch 17/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0965 - val_loss: 0.1011\n",
      "Epoch 18/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0960 - val_loss: 0.1006\n",
      "Epoch 19/100\n",
      "5702/5702 [==============================] - 5s 846us/step - loss: 0.0956 - val_loss: 0.1001\n",
      "Epoch 20/100\n",
      "5702/5702 [==============================] - 5s 865us/step - loss: 0.0952 - val_loss: 0.0996\n",
      "Epoch 21/100\n",
      "5702/5702 [==============================] - 5s 950us/step - loss: 0.0948 - val_loss: 0.0991\n",
      "Epoch 22/100\n",
      "5702/5702 [==============================] - 5s 821us/step - loss: 0.0944 - val_loss: 0.0987\n",
      "Epoch 23/100\n",
      "5702/5702 [==============================] - 5s 834us/step - loss: 0.0941 - val_loss: 0.0983\n",
      "Epoch 24/100\n",
      "5702/5702 [==============================] - 5s 890us/step - loss: 0.0937 - val_loss: 0.0979\n",
      "Epoch 25/100\n",
      "5702/5702 [==============================] - 5s 856us/step - loss: 0.0934 - val_loss: 0.0975\n",
      "Epoch 26/100\n",
      "5702/5702 [==============================] - 5s 868us/step - loss: 0.0930 - val_loss: 0.0971\n",
      "Epoch 27/100\n",
      "5702/5702 [==============================] - 5s 886us/step - loss: 0.0927 - val_loss: 0.0967\n",
      "Epoch 28/100\n",
      "5702/5702 [==============================] - 5s 859us/step - loss: 0.0923 - val_loss: 0.0964\n",
      "Epoch 29/100\n",
      "5702/5702 [==============================] - 5s 952us/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 30/100\n",
      "5702/5702 [==============================] - 5s 821us/step - loss: 0.0917 - val_loss: 0.0957\n",
      "Epoch 31/100\n",
      "5702/5702 [==============================] - 5s 963us/step - loss: 0.0914 - val_loss: 0.0954\n",
      "Epoch 32/100\n",
      "5702/5702 [==============================] - 5s 909us/step - loss: 0.0911 - val_loss: 0.0951\n",
      "Epoch 33/100\n",
      "5702/5702 [==============================] - 5s 859us/step - loss: 0.0908 - val_loss: 0.0947\n",
      "Epoch 34/100\n",
      "5702/5702 [==============================] - 5s 840us/step - loss: 0.0905 - val_loss: 0.0944\n",
      "Epoch 35/100\n",
      "5702/5702 [==============================] - 4s 780us/step - loss: 0.0902 - val_loss: 0.0942\n",
      "Epoch 36/100\n",
      "5702/5702 [==============================] - 4s 776us/step - loss: 0.0900 - val_loss: 0.0939\n",
      "Epoch 37/100\n",
      "5702/5702 [==============================] - 4s 767us/step - loss: 0.0897 - val_loss: 0.0936\n",
      "Epoch 38/100\n",
      "5702/5702 [==============================] - 4s 762us/step - loss: 0.0894 - val_loss: 0.0933\n",
      "Epoch 39/100\n",
      "5702/5702 [==============================] - 4s 759us/step - loss: 0.0892 - val_loss: 0.0931\n",
      "Epoch 40/100\n",
      "5702/5702 [==============================] - 4s 762us/step - loss: 0.0889 - val_loss: 0.0928\n",
      "Epoch 41/100\n",
      "5702/5702 [==============================] - 4s 761us/step - loss: 0.0886 - val_loss: 0.0925ss: 0.08\n",
      "Epoch 42/100\n",
      "5702/5702 [==============================] - 4s 753us/step - loss: 0.0884 - val_loss: 0.0923\n",
      "Epoch 43/100\n",
      "5702/5702 [==============================] - 4s 757us/step - loss: 0.0882 - val_loss: 0.0921\n",
      "Epoch 44/100\n",
      "5702/5702 [==============================] - 4s 769us/step - loss: 0.0879 - val_loss: 0.0918\n",
      "Epoch 45/100\n",
      "5702/5702 [==============================] - 4s 780us/step - loss: 0.0877 - val_loss: 0.0916 loss: 0.\n",
      "Epoch 46/100\n",
      "5702/5702 [==============================] - 4s 775us/step - loss: 0.0874 - val_loss: 0.0914\n",
      "Epoch 47/100\n",
      "5702/5702 [==============================] - 4s 772us/step - loss: 0.0872 - val_loss: 0.0912\n",
      "Epoch 48/100\n",
      "5702/5702 [==============================] - 4s 765us/step - loss: 0.0870 - val_loss: 0.0910\n",
      "Epoch 49/100\n",
      "5702/5702 [==============================] - 4s 758us/step - loss: 0.0868 - val_loss: 0.0908\n",
      "Epoch 50/100\n",
      "5702/5702 [==============================] - 4s 785us/step - loss: 0.0866 - val_loss: 0.0906\n",
      "Epoch 51/100\n",
      "5702/5702 [==============================] - 4s 768us/step - loss: 0.0863 - val_loss: 0.0904\n",
      "Epoch 52/100\n",
      "5702/5702 [==============================] - 4s 765us/step - loss: 0.0861 - val_loss: 0.0902\n",
      "Epoch 53/100\n",
      "5702/5702 [==============================] - 4s 745us/step - loss: 0.0859 - val_loss: 0.0900\n",
      "Epoch 54/100\n",
      "5702/5702 [==============================] - 4s 750us/step - loss: 0.0857 - val_loss: 0.0898\n",
      "Epoch 55/100\n",
      "5702/5702 [==============================] - 4s 760us/step - loss: 0.0855 - val_loss: 0.0896\n",
      "Epoch 56/100\n",
      "5702/5702 [==============================] - 4s 729us/step - loss: 0.0853 - val_loss: 0.0894\n",
      "Epoch 57/100\n",
      "5702/5702 [==============================] - 4s 789us/step - loss: 0.0851 - val_loss: 0.0893\n",
      "Epoch 58/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0849 - val_loss: 0.0891\n",
      "Epoch 59/100\n",
      "5702/5702 [==============================] - 4s 744us/step - loss: 0.0847 - val_loss: 0.0889\n",
      "Epoch 60/100\n",
      "5702/5702 [==============================] - 4s 725us/step - loss: 0.0845 - val_loss: 0.08883s - loss: 0\n",
      "Epoch 61/100\n",
      "5702/5702 [==============================] - 4s 731us/step - loss: 0.0844 - val_loss: 0.0886\n",
      "Epoch 62/100\n",
      "5702/5702 [==============================] - 4s 719us/step - loss: 0.0842 - val_loss: 0.0885\n",
      "Epoch 63/100\n",
      "5702/5702 [==============================] - 4s 756us/step - loss: 0.0840 - val_loss: 0.0883\n",
      "Epoch 64/100\n",
      "5702/5702 [==============================] - 4s 748us/step - loss: 0.0838 - val_loss: 0.0882\n",
      "Epoch 65/100\n",
      "5702/5702 [==============================] - 4s 743us/step - loss: 0.0836 - val_loss: 0.0880\n",
      "Epoch 66/100\n",
      "5702/5702 [==============================] - 4s 742us/step - loss: 0.0835 - val_loss: 0.0879\n",
      "Epoch 67/100\n",
      "5702/5702 [==============================] - 4s 764us/step - loss: 0.0833 - val_loss: 0.0877\n",
      "Epoch 68/100\n",
      "5702/5702 [==============================] - 4s 722us/step - loss: 0.0831 - val_loss: 0.0876\n",
      "Epoch 69/100\n",
      "5702/5702 [==============================] - 4s 784us/step - loss: 0.0829 - val_loss: 0.0875\n",
      "Epoch 70/100\n",
      "5702/5702 [==============================] - 5s 840us/step - loss: 0.0828 - val_loss: 0.0873\n",
      "Epoch 71/100\n",
      "5702/5702 [==============================] - 5s 790us/step - loss: 0.0826 - val_loss: 0.0872\n",
      "Epoch 72/100\n",
      "5702/5702 [==============================] - 4s 741us/step - loss: 0.0824 - val_loss: 0.0871\n",
      "Epoch 73/100\n",
      "5702/5702 [==============================] - 4s 736us/step - loss: 0.0823 - val_loss: 0.0870\n",
      "Epoch 74/100\n",
      "5702/5702 [==============================] - 5s 858us/step - loss: 0.0821 - val_loss: 0.0868\n",
      "Epoch 75/100\n",
      "5702/5702 [==============================] - 5s 795us/step - loss: 0.0820 - val_loss: 0.0867\n",
      "Epoch 76/100\n",
      "5702/5702 [==============================] - 4s 693us/step - loss: 0.0818 - val_loss: 0.0866\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5702/5702 [==============================] - 4s 637us/step - loss: 0.0816 - val_loss: 0.0865\n",
      "Epoch 78/100\n",
      "5702/5702 [==============================] - 4s 638us/step - loss: 0.0815 - val_loss: 0.0864\n",
      "Epoch 79/100\n",
      "5702/5702 [==============================] - 4s 641us/step - loss: 0.0813 - val_loss: 0.0862\n",
      "Epoch 80/100\n",
      "5702/5702 [==============================] - 5s 961us/step - loss: 0.0812 - val_loss: 0.0861\n",
      "Epoch 81/100\n",
      "5702/5702 [==============================] - 4s 659us/step - loss: 0.0810 - val_loss: 0.0860\n",
      "Epoch 82/100\n",
      "5702/5702 [==============================] - 4s 675us/step - loss: 0.0809 - val_loss: 0.0859\n",
      "Epoch 83/100\n",
      "5702/5702 [==============================] - 5s 814us/step - loss: 0.0807 - val_loss: 0.0858: 0s - loss:\n",
      "Epoch 84/100\n",
      "5702/5702 [==============================] - 4s 711us/step - loss: 0.0806 - val_loss: 0.0857\n",
      "Epoch 85/100\n",
      "5702/5702 [==============================] - 5s 868us/step - loss: 0.0804 - val_loss: 0.0856\n",
      "Epoch 86/100\n",
      "5702/5702 [==============================] - 4s 698us/step - loss: 0.0803 - val_loss: 0.0855\n",
      "Epoch 87/100\n",
      "5702/5702 [==============================] - 4s 720us/step - loss: 0.0801 - val_loss: 0.0854- loss: 0\n",
      "Epoch 88/100\n",
      "5702/5702 [==============================] - 5s 803us/step - loss: 0.0800 - val_loss: 0.0853\n",
      "Epoch 89/100\n",
      "5702/5702 [==============================] - 5s 950us/step - loss: 0.0799 - val_loss: 0.0852\n",
      "Epoch 90/100\n",
      "5702/5702 [==============================] - 5s 844us/step - loss: 0.0797 - val_loss: 0.0851\n",
      "Epoch 91/100\n",
      "5702/5702 [==============================] - 5s 870us/step - loss: 0.0796 - val_loss: 0.0850\n",
      "Epoch 92/100\n",
      "5702/5702 [==============================] - 5s 864us/step - loss: 0.0794 - val_loss: 0.0849\n",
      "Epoch 93/100\n",
      "5702/5702 [==============================] - 5s 918us/step - loss: 0.0793 - val_loss: 0.0848\n",
      "Epoch 94/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0792 - val_loss: 0.0847\n",
      "Epoch 95/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0790 - val_loss: 0.0847\n",
      "Epoch 96/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0789 - val_loss: 0.0846- ETA: 0s - loss:\n",
      "Epoch 97/100\n",
      "5702/5702 [==============================] - 6s 1ms/step - loss: 0.0788 - val_loss: 0.08450\n",
      "Epoch 98/100\n",
      "5702/5702 [==============================] - 5s 866us/step - loss: 0.0786 - val_loss: 0.0844\n",
      "Epoch 99/100\n",
      "5702/5702 [==============================] - 4s 725us/step - loss: 0.0785 - val_loss: 0.0843\n",
      "Epoch 100/100\n",
      "5702/5702 [==============================] - 5s 939us/step - loss: 0.0784 - val_loss: 0.0842\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "(array([(  0, 182, 0.73049451,   0. ), (  1, 177, 0.68768362,   0.2),\n",
      "       (  2, 156, 0.65551839,   0. ), (  3,  18, 0.36141304,  96.8),\n",
      "       (  4,  90, 0.57589286,   2. ), (  5,   2, 0.59      ,  32.6),\n",
      "       (  6,   0, 0.        , 100. ), (  7,  12, 0.61315789,   8.8),\n",
      "       (  8,   0, 0.        , 100. ), (  9,   0, 0.        , 100. ),\n",
      "       ( 10,   0, 0.        , 100. ), ( 11, 117, 0.64635495,   0. ),\n",
      "       ( 12,  40, 0.58179012,   5.8), ( 13, 104, 0.63628336,   0. ),\n",
      "       ( 14,  19, 0.62007478,   4.6), ( 15,  54, 0.5518018 ,  14.6),\n",
      "       ( 16,  12, 0.57324561,  18.6), ( 17,  17, 0.3990461 ,  92.6),\n",
      "       ( 18,   2, 0.3925    ,  70.2), ( 19,   0, 0.        , 100. ),\n",
      "       ( 20,   0, 0.        , 100. ), ( 21,   0, 0.        , 100. ),\n",
      "       ( 22,  57, 0.523049  ,  29.6), ( 23,  43, 0.43644873,  90.4),\n",
      "       ( 24,   8, 0.47551546,  61. ), ( 25,  10, 0.634375  ,   7. ),\n",
      "       ( 26,   0, 0.        , 100. ), ( 27,   4, 0.30555556,  90.2),\n",
      "       ( 28,   0, 0.        , 100. ), ( 29,   1, 0.33830846,  68.6),\n",
      "       ( 30,   0, 0.        , 100. ), ( 31,   0, 0.        , 100. ),\n",
      "       ( 32,   0, 0.        , 100. ), ( 33,   0, 0.        , 100. ),\n",
      "       ( 34,   2, 0.6375    ,  28.4), ( 35,   0, 0.        , 100. ),\n",
      "       ( 36,   7, 0.64102564,   9.2), ( 37,   0, 0.        , 100. ),\n",
      "       ( 38,   0, 0.        , 100. ), ( 39,  22, 0.49242424,  54.6),\n",
      "       ( 40,  27, 0.60592593,   3.2), ( 41,   0, 0.        , 100. ),\n",
      "       ( 42,   0, 0.        , 100. ), ( 43,   0, 0.        , 100. ),\n",
      "       ( 44,   0, 0.        , 100. ), ( 45,   0, 0.        , 100. ),\n",
      "       ( 46,   0, 0.        , 100. ), ( 47,   3, 0.44053601,  63. ),\n",
      "       ( 48,  58, 0.5493295 ,  13.4), ( 49,   0, 0.        , 100. ),\n",
      "       ( 50,   0, 0.        , 100. ), ( 51,   4, 0.71212121,   7. ),\n",
      "       ( 52,   1, 0.25373134,  74.8), ( 53,   0, 0.        , 100. ),\n",
      "       ( 54,   1, 0.94527363,   5.8), ( 55,  30, 0.5874031 ,   7.4),\n",
      "       ( 56,  13, 0.36019536,  94.2), ( 57,   2, 0.515     ,  47. ),\n",
      "       ( 58,   0, 0.        , 100. ), ( 59,   1, 0.05970149,  92.8),\n",
      "       ( 60,   0, 0.        , 100. ), ( 61,   0, 0.        , 100. ),\n",
      "       ( 62,  42, 0.56428571,   9.4), ( 63,   0, 0.        , 100. ),\n",
      "       ( 64,   4, 0.86868687,   0.6), ( 65,   4, 0.81186869,   1.8),\n",
      "       ( 66,   0, 0.        , 100. ), ( 67,   3, 0.7001675 ,  13. ),\n",
      "       ( 68,   0, 0.        , 100. ), ( 69,   0, 0.        , 100. ),\n",
      "       ( 70,   0, 0.        , 100. ), ( 71,  10, 0.725     ,   1.2),\n",
      "       ( 72,   0, 0.        , 100. ), ( 73,  13, 0.50549451,  46.6),\n",
      "       ( 74,   0, 0.        , 100. ), ( 75,   3, 0.42043551,  66.2),\n",
      "       ( 76,   0, 0.        , 100. ), ( 77,   0, 0.        , 100. ),\n",
      "       ( 78,   0, 0.        , 100. ), ( 79,   0, 0.        , 100. ),\n",
      "       ( 80,   0, 0.        , 100. ), ( 81,   0, 0.        , 100. ),\n",
      "       ( 82,   0, 0.        , 100. ), ( 83,  71, 0.4834964 ,  63.4),\n",
      "       ( 84,  20, 0.51346154,  39.8), ( 85, 109, 0.68975042,   0. ),\n",
      "       ( 86,   0, 0.        , 100. ), ( 87, 174, 0.79371921,   0. ),\n",
      "       ( 88,   0, 0.        , 100. ), ( 89,   0, 0.        , 100. ),\n",
      "       ( 90,   0, 0.        , 100. ), ( 91,   0, 0.        , 100. ),\n",
      "       ( 92,   0, 0.        , 100. ), ( 93,   0, 0.        , 100. ),\n",
      "       ( 94,   0, 0.        , 100. ), ( 95,   0, 0.        , 100. ),\n",
      "       ( 96,   0, 0.        , 100. ), ( 97,  43, 0.71522598,   0. ),\n",
      "       ( 98,   7, 0.47399267,  63.2), ( 99,  23, 0.40296332,  93.2),\n",
      "       (100,  29, 0.58341638,  10.8), (101,  53, 0.65417247,   0.2),\n",
      "       (102,   4, 0.73611111,   6. ), (103,   0, 0.        , 100. ),\n",
      "       (104,   0, 0.        , 100. ), (105,   0, 0.        , 100. ),\n",
      "       (106,   0, 0.        , 100. ), (107,   0, 0.        , 100. ),\n",
      "       (108,   0, 0.        , 100. ), (109,  15, 0.59821747,  12.2),\n",
      "       (110,   0, 0.        , 100. ), (111,  58, 0.45545977,  82.8),\n",
      "       (112,  69, 0.71199738,   0. ), (113,   0, 0.        , 100. ),\n",
      "       (114,   0, 0.        , 100. ), (115,   0, 0.        , 100. ),\n",
      "       (116,   0, 0.        , 100. ), (117,   0, 0.        , 100. ),\n",
      "       (118,   3, 0.56951424,  35.8), (119,   0, 0.        , 100. ),\n",
      "       (120,   0, 0.        , 100. ), (121,   0, 0.        , 100. ),\n",
      "       (122,   0, 0.        , 100. ), (123,   0, 0.        , 100. ),\n",
      "       (124,   0, 0.        , 100. ), (125,   5, 0.46700508,  58. ),\n",
      "       (126,  23, 0.47631771,  65. ), (127,   9, 0.3189407 ,  97.4),\n",
      "       (128,   4, 0.36489899,  81.6), (129,   0, 0.        , 100. ),\n",
      "       (130,   0, 0.        , 100. ), (131,   0, 0.        , 100. ),\n",
      "       (132,   1, 0.54228856,  47. ), (133,   2, 0.505     ,  48.4),\n",
      "       (134,  40, 0.64089506,   0.2), (135,  17, 0.75357711,   0. ),\n",
      "       (136,  71, 0.61068702,   0.6), (137,  11, 0.61113755,   8.4),\n",
      "       (138,   0, 0.        , 100. ), (139,   0, 0.        , 100. ),\n",
      "       (140,   0, 0.        , 100. ), (141,   0, 0.        , 100. ),\n",
      "       (142,  20, 0.61428571,   5.4), (143,   0, 0.        , 100. ),\n",
      "       (144,   0, 0.        , 100. ), (145,   0, 0.        , 100. ),\n",
      "       (146,   0, 0.        , 100. ), (147,   0, 0.        , 100. ),\n",
      "       (148,   3, 0.76046901,   5. ), (149,   0, 0.        , 100. ),\n",
      "       (150,  13, 0.64713065,   3.8), (151,   0, 0.        , 100. ),\n",
      "       (152,   0, 0.        , 100. ), (153,   0, 0.        , 100. ),\n",
      "       (154,   0, 0.        , 100. ), (155,   0, 0.        , 100. ),\n",
      "       (156,   0, 0.        , 100. ), (157,   0, 0.        , 100. ),\n",
      "       (158,   0, 0.        , 100. ), (159,   0, 0.        , 100. ),\n",
      "       (160,   0, 0.        , 100. ), (161,   0, 0.        , 100. ),\n",
      "       (162,   0, 0.        , 100. ), (163,   0, 0.        , 100. ),\n",
      "       (164,   4, 0.48358586,  56.2), (165,   0, 0.        , 100. ),\n",
      "       (166,   0, 0.        , 100. ), (167,   0, 0.        , 100. ),\n",
      "       (168,  39, 0.49834828,  51.4), (169,   0, 0.        , 100. ),\n",
      "       (170,   7, 0.32161172,  94.4), (171,   0, 0.        , 100. ),\n",
      "       (172,   0, 0.        , 100. ), (173,   0, 0.        , 100. ),\n",
      "       (174,   0, 0.        , 100. ), (175,   0, 0.        , 100. ),\n",
      "       (176,   6, 0.43622449,  68.4), (177,   0, 0.        , 100. ),\n",
      "       (178,  29, 0.55371736,  19.2), (179,   6, 0.72193878,   2.6),\n",
      "       (180,  11, 0.59019515,  17.6), (181,   6, 0.3877551 ,  83.6),\n",
      "       (182,   3, 0.53768844,  38.6), (183,  45, 0.64217976,   0.2),\n",
      "       (184,   0, 0.        , 100. ), (185,   0, 0.        , 100. ),\n",
      "       (186,   0, 0.        , 100. ), (187,   4, 0.34090909,  87. ),\n",
      "       (188,   0, 0.        , 100. ), (189,   0, 0.        , 100. ),\n",
      "       (190,   0, 0.        , 100. ), (191,   0, 0.        , 100. ),\n",
      "       (192,   0, 0.        , 100. ), (193,   0, 0.        , 100. ),\n",
      "       (194,   0, 0.        , 100. ), (195,   0, 0.        , 100. ),\n",
      "       (196,   0, 0.        , 100. ), (197,   0, 0.        , 100. ),\n",
      "       (198,   0, 0.        , 100. ), (199,   0, 0.        , 100. ),\n",
      "       (200,   0, 0.        , 100. ), (201,   0, 0.        , 100. ),\n",
      "       (202,   0, 0.        , 100. ), (203,   0, 0.        , 100. ),\n",
      "       (204,   0, 0.        , 100. ), (205,   0, 0.        , 100. ),\n",
      "       (206,   0, 0.        , 100. ), (207,   0, 0.        , 100. ),\n",
      "       (208,   0, 0.        , 100. ), (209,   0, 0.        , 100. ),\n",
      "       (210,   0, 0.        , 100. ), (211,   0, 0.        , 100. ),\n",
      "       (212,   0, 0.        , 100. ), (213,   0, 0.        , 100. ),\n",
      "       (214,   0, 0.        , 100. ), (215,   0, 0.        , 100. ),\n",
      "       (216,   0, 0.        , 100. ), (217,   0, 0.        , 100. ),\n",
      "       (218,   0, 0.        , 100. ), (219,   0, 0.        , 100. ),\n",
      "       (220,   0, 0.        , 100. ), (221,   0, 0.        , 100. ),\n",
      "       (222,   0, 0.        , 100. ), (223,   0, 0.        , 100. ),\n",
      "       (224,   0, 0.        , 100. ), (225,   0, 0.        , 100. ),\n",
      "       (226,   0, 0.        , 100. ), (227,   0, 0.        , 100. ),\n",
      "       (228,   0, 0.        , 100. ), (229,   0, 0.        , 100. ),\n",
      "       (230,   0, 0.        , 100. ), (231,   0, 0.        , 100. ),\n",
      "       (232,   0, 0.        , 100. ), (233,   0, 0.        , 100. ),\n",
      "       (234,   0, 0.        , 100. ), (235,   0, 0.        , 100. ),\n",
      "       (236,   0, 0.        , 100. ), (237,   0, 0.        , 100. ),\n",
      "       (238,   0, 0.        , 100. ), (239,   0, 0.        , 100. ),\n",
      "       (240,   0, 0.        , 100. ), (241,   0, 0.        , 100. ),\n",
      "       (242,   0, 0.        , 100. ), (243,   0, 0.        , 100. ),\n",
      "       (244,   0, 0.        , 100. ), (245,   0, 0.        , 100. ),\n",
      "       (246,   0, 0.        , 100. ), (247,   0, 0.        , 100. ),\n",
      "       (248,   0, 0.        , 100. ), (249,   0, 0.        , 100. ),\n",
      "       (250,   0, 0.        , 100. ), (251,   0, 0.        , 100. ),\n",
      "       (252,   0, 0.        , 100. ), (253,   0, 0.        , 100. ),\n",
      "       (254,   0, 0.        , 100. ), (255,   0, 0.        , 100. ),\n",
      "       (256,   0, 0.        , 100. ), (257,   0, 0.        , 100. ),\n",
      "       (258,   0, 0.        , 100. ), (259,   0, 0.        , 100. ),\n",
      "       (260,   0, 0.        , 100. ), (261,   0, 0.        , 100. ),\n",
      "       (262,   0, 0.        , 100. ), (263,   0, 0.        , 100. ),\n",
      "       (264,   0, 0.        , 100. ), (265,   0, 0.        , 100. ),\n",
      "       (266,   0, 0.        , 100. ), (267,   0, 0.        , 100. ),\n",
      "       (268,   0, 0.        , 100. ), (269,   0, 0.        , 100. ),\n",
      "       (270,   0, 0.        , 100. ), (271,   0, 0.        , 100. ),\n",
      "       (272,   0, 0.        , 100. ), (273, 103, 0.59752868,   1. ),\n",
      "       (274, 182, 0.60467033,   5.6), (275,  11, 0.32413137,  97.4),\n",
      "       (276,   0, 0.        , 100. ), (277,  21, 0.46803473,  68.2),\n",
      "       (278,  97, 0.52312224,  28.6), (279,  69, 0.48316443,  63.2),\n",
      "       (280,  26, 0.66979895,   0. ), (281,  30, 0.59282946,   4.6),\n",
      "       (282,  13, 0.7049247 ,   0.4), (283,  15, 0.36470588,  97. ),\n",
      "       (284,   7, 0.48717949,  52.2), (285,   4, 0.38762626,  75.8),\n",
      "       (286, 115, 0.61669165,   0. ), (287,   0, 0.        , 100. ),\n",
      "       (288,   0, 0.        , 100. ), (289,   4, 0.49494949,  53.6),\n",
      "       (290,   0, 0.        , 100. ), (291,   0, 0.        , 100. ),\n",
      "       (292,   0, 0.        , 100. ), (293,   0, 0.        , 100. ),\n",
      "       (294, 202, 0.        , 100. ), (295,   4, 0.61363636,  24. ),\n",
      "       (296,   3, 0.68676717,  13.2), (297,   4, 0.45075758,  61. ),\n",
      "       (298,   1, 0.6318408 ,  32.6), (299, 188, 0.70896657,   0.4),\n",
      "       (300,  80, 0.52182377,  30.4), (301, 191, 0.62113279,  12.2),\n",
      "       (302,  75, 0.50918635,  42. ), (303,   0, 0.        , 100. ),\n",
      "       (304,  85, 0.58149824,   2. ), (305,   1, 0.99004975,   1.8),\n",
      "       (306, 194, 0.42847938,  76.6), (307,   0, 0.        , 100. ),\n",
      "       (308,   0, 0.        , 100. ), (309,   0, 0.        , 100. ),\n",
      "       (310,   0, 0.        , 100. ), (311,   0, 0.        , 100. ),\n",
      "       (312,   0, 0.        , 100. ), (313,   0, 0.        , 100. ),\n",
      "       (314,   0, 0.        , 100. ), (315,   0, 0.        , 100. ),\n",
      "       (316,   0, 0.        , 100. ), (317,   0, 0.        , 100. ),\n",
      "       (318,   0, 0.        , 100. ), (319,   0, 0.        , 100. )],\n",
      "      dtype=[('fp_id', '<i4'), ('nonzeros', '<i4'), ('auc', '<f8'), ('auc_percent', '<f8')]), array([[0.5956044 , 0.4717033 , 0.4543956 , ..., 0.55357143, 0.43681319,\n",
      "        0.50769231],\n",
      "       [0.55615819, 0.56836158, 0.50553672, ..., 0.61898305, 0.49627119,\n",
      "        0.52248588],\n",
      "       [0.58862876, 0.4960981 , 0.50125418, ..., 0.56396321, 0.57887402,\n",
      "        0.52968227],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]))\n"
     ]
    }
   ],
   "source": [
    "# Training network 1 (exclude links)\n",
    "epochs = 100\n",
    "x_train_spectra = np.log(gnps_spectra+1)\n",
    "x_train_fingerprints = gnps_fingerprints.values\n",
    "x_test_spectra = np.log(test_spectra+1)\n",
    "\n",
    "enc1 = simplified_fingerprint_model(x_train_spectra, x_train_fingerprints, epochs=epochs)\n",
    "\n",
    "actual = test_fingerprint.values\n",
    "predicted = enc1.predict(x_test_spectra)\n",
    "\n",
    "print(compute_auc(320, actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training network 1 (include links)\n",
    "epochs = 100\n",
    "x_train_spectra = np.log(spectra+1)\n",
    "x_train_fingerprints = fingerprints.values\n",
    "\n",
    "enc1 = simplified_fingerprint_model(x_train_spectra, x_train_fingerprints, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training network 2 (exclude links)\n",
    "epochs = 100\n",
    "x_train_fingerprints = mibig_filtered_fingerprints\n",
    "x_train_families = mibig_filtered_families\n",
    "\n",
    "enc2 = simplified_family_model(x_train_fingerprints.values, x_train_families.values, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\nnpredict\\Code\\Python\\nn_interface.py:157: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  auto_model = Model(input=input_layer, output=out_layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1231 samples, validate on 137 samples\n",
      "Epoch 1/100\n",
      "1231/1231 [==============================] - 1s 902us/step - loss: 0.5226 - val_loss: 0.3818\n",
      "Epoch 2/100\n",
      "1231/1231 [==============================] - 1s 451us/step - loss: 0.3585 - val_loss: 0.3259\n",
      "Epoch 3/100\n",
      "1231/1231 [==============================] - 1s 635us/step - loss: 0.3297 - val_loss: 0.3123\n",
      "Epoch 4/100\n",
      "1231/1231 [==============================] - 1s 692us/step - loss: 0.3170 - val_loss: 0.3045\n",
      "Epoch 5/100\n",
      "1231/1231 [==============================] - 1s 563us/step - loss: 0.3073 - val_loss: 0.2983\n",
      "Epoch 6/100\n",
      "1231/1231 [==============================] - 1s 634us/step - loss: 0.2990 - val_loss: 0.2928\n",
      "Epoch 7/100\n",
      "1231/1231 [==============================] - 1s 553us/step - loss: 0.2917 - val_loss: 0.2878\n",
      "Epoch 8/100\n",
      "1231/1231 [==============================] - 1s 469us/step - loss: 0.2852 - val_loss: 0.2833\n",
      "Epoch 9/100\n",
      "1231/1231 [==============================] - 0s 395us/step - loss: 0.2793 - val_loss: 0.2792\n",
      "Epoch 10/100\n",
      "1231/1231 [==============================] - 1s 505us/step - loss: 0.2740 - val_loss: 0.2754\n",
      "Epoch 11/100\n",
      "1231/1231 [==============================] - 1s 505us/step - loss: 0.2693 - val_loss: 0.2719\n",
      "Epoch 12/100\n",
      "1231/1231 [==============================] - 1s 728us/step - loss: 0.2649 - val_loss: 0.2685\n",
      "Epoch 13/100\n",
      "1231/1231 [==============================] - 1s 758us/step - loss: 0.2608 - val_loss: 0.2654\n",
      "Epoch 14/100\n",
      "1231/1231 [==============================] - 1s 724us/step - loss: 0.2569 - val_loss: 0.2625\n",
      "Epoch 15/100\n",
      "1231/1231 [==============================] - 1s 497us/step - loss: 0.2533 - val_loss: 0.2598\n",
      "Epoch 16/100\n",
      "1231/1231 [==============================] - 1s 487us/step - loss: 0.2499 - val_loss: 0.2572\n",
      "Epoch 17/100\n",
      "1231/1231 [==============================] - 1s 534us/step - loss: 0.2467 - val_loss: 0.2548\n",
      "Epoch 18/100\n",
      "1231/1231 [==============================] - 1s 651us/step - loss: 0.2436 - val_loss: 0.2526\n",
      "Epoch 19/100\n",
      "1231/1231 [==============================] - 1s 761us/step - loss: 0.2407 - val_loss: 0.2505\n",
      "Epoch 20/100\n",
      "1231/1231 [==============================] - 1s 648us/step - loss: 0.2379 - val_loss: 0.2485\n",
      "Epoch 21/100\n",
      "1231/1231 [==============================] - 1s 553us/step - loss: 0.2353 - val_loss: 0.2466\n",
      "Epoch 22/100\n",
      "1231/1231 [==============================] - 1s 575us/step - loss: 0.2328 - val_loss: 0.2449\n",
      "Epoch 23/100\n",
      "1231/1231 [==============================] - 1s 514us/step - loss: 0.2304 - val_loss: 0.2433\n",
      "Epoch 24/100\n",
      "1231/1231 [==============================] - 1s 646us/step - loss: 0.2281 - val_loss: 0.2417\n",
      "Epoch 25/100\n",
      "1231/1231 [==============================] - 1s 440us/step - loss: 0.2259 - val_loss: 0.2402\n",
      "Epoch 26/100\n",
      "1231/1231 [==============================] - 1s 486us/step - loss: 0.2238 - val_loss: 0.2388\n",
      "Epoch 27/100\n",
      "1231/1231 [==============================] - 1s 555us/step - loss: 0.2218 - val_loss: 0.2375\n",
      "Epoch 28/100\n",
      "1231/1231 [==============================] - 1s 715us/step - loss: 0.2199 - val_loss: 0.2363\n",
      "Epoch 29/100\n",
      "1231/1231 [==============================] - 1s 597us/step - loss: 0.2181 - val_loss: 0.2351\n",
      "Epoch 30/100\n",
      "1231/1231 [==============================] - 1s 713us/step - loss: 0.2163 - val_loss: 0.2339\n",
      "Epoch 31/100\n",
      "1231/1231 [==============================] - 1s 551us/step - loss: 0.2146 - val_loss: 0.2329\n",
      "Epoch 32/100\n",
      "1231/1231 [==============================] - 1s 546us/step - loss: 0.2129 - val_loss: 0.2318\n",
      "Epoch 33/100\n",
      "1231/1231 [==============================] - 1s 696us/step - loss: 0.2113 - val_loss: 0.2308\n",
      "Epoch 34/100\n",
      "1231/1231 [==============================] - 1s 573us/step - loss: 0.2097 - val_loss: 0.2299\n",
      "Epoch 35/100\n",
      "1231/1231 [==============================] - 1s 582us/step - loss: 0.2082 - val_loss: 0.2290\n",
      "Epoch 36/100\n",
      "1231/1231 [==============================] - 0s 357us/step - loss: 0.2067 - val_loss: 0.2281\n",
      "Epoch 37/100\n",
      "1231/1231 [==============================] - 1s 516us/step - loss: 0.2053 - val_loss: 0.2273\n",
      "Epoch 38/100\n",
      "1231/1231 [==============================] - 1s 514us/step - loss: 0.2039 - val_loss: 0.2265\n",
      "Epoch 39/100\n",
      "1231/1231 [==============================] - 1s 476us/step - loss: 0.2026 - val_loss: 0.2257\n",
      "Epoch 40/100\n",
      "1231/1231 [==============================] - 1s 554us/step - loss: 0.2013 - val_loss: 0.2249\n",
      "Epoch 41/100\n",
      "1231/1231 [==============================] - 1s 557us/step - loss: 0.2000 - val_loss: 0.2242\n",
      "Epoch 42/100\n",
      "1231/1231 [==============================] - 1s 577us/step - loss: 0.1987 - val_loss: 0.2235\n",
      "Epoch 43/100\n",
      "1231/1231 [==============================] - 1s 468us/step - loss: 0.1975 - val_loss: 0.2228\n",
      "Epoch 44/100\n",
      "1231/1231 [==============================] - 1s 486us/step - loss: 0.1963 - val_loss: 0.2221\n",
      "Epoch 45/100\n",
      "1231/1231 [==============================] - 1s 434us/step - loss: 0.1952 - val_loss: 0.2215\n",
      "Epoch 46/100\n",
      "1231/1231 [==============================] - 1s 501us/step - loss: 0.1940 - val_loss: 0.2209\n",
      "Epoch 47/100\n",
      "1231/1231 [==============================] - 1s 489us/step - loss: 0.1929 - val_loss: 0.2203\n",
      "Epoch 48/100\n",
      "1231/1231 [==============================] - 0s 300us/step - loss: 0.1918 - val_loss: 0.2197\n",
      "Epoch 49/100\n",
      "1231/1231 [==============================] - 1s 441us/step - loss: 0.1907 - val_loss: 0.2192\n",
      "Epoch 50/100\n",
      "1231/1231 [==============================] - 0s 405us/step - loss: 0.1897 - val_loss: 0.2187\n",
      "Epoch 51/100\n",
      "1231/1231 [==============================] - 1s 498us/step - loss: 0.1886 - val_loss: 0.2181\n",
      "Epoch 52/100\n",
      "1231/1231 [==============================] - 0s 366us/step - loss: 0.1876 - val_loss: 0.2176\n",
      "Epoch 53/100\n",
      "1231/1231 [==============================] - 1s 416us/step - loss: 0.1866 - val_loss: 0.2171\n",
      "Epoch 54/100\n",
      "1231/1231 [==============================] - 1s 545us/step - loss: 0.1857 - val_loss: 0.2167\n",
      "Epoch 55/100\n",
      "1231/1231 [==============================] - 1s 498us/step - loss: 0.1847 - val_loss: 0.2162\n",
      "Epoch 56/100\n",
      "1231/1231 [==============================] - 1s 526us/step - loss: 0.1837 - val_loss: 0.2157\n",
      "Epoch 57/100\n",
      "1231/1231 [==============================] - 1s 448us/step - loss: 0.1828 - val_loss: 0.2153\n",
      "Epoch 58/100\n",
      "1231/1231 [==============================] - 1s 590us/step - loss: 0.1818 - val_loss: 0.2149\n",
      "Epoch 59/100\n",
      "1231/1231 [==============================] - 1s 443us/step - loss: 0.1809 - val_loss: 0.2145\n",
      "Epoch 60/100\n",
      "1231/1231 [==============================] - 1s 530us/step - loss: 0.1800 - val_loss: 0.2141\n",
      "Epoch 61/100\n",
      "1231/1231 [==============================] - 1s 589us/step - loss: 0.1791 - val_loss: 0.2137\n",
      "Epoch 62/100\n",
      "1231/1231 [==============================] - 1s 563us/step - loss: 0.1782 - val_loss: 0.2134\n",
      "Epoch 63/100\n",
      "1231/1231 [==============================] - 1s 548us/step - loss: 0.1774 - val_loss: 0.2130\n",
      "Epoch 64/100\n",
      "1231/1231 [==============================] - 1s 545us/step - loss: 0.1765 - val_loss: 0.2127\n",
      "Epoch 65/100\n",
      "1231/1231 [==============================] - 1s 568us/step - loss: 0.1757 - val_loss: 0.2124\n",
      "Epoch 66/100\n",
      "1231/1231 [==============================] - 1s 559us/step - loss: 0.1748 - val_loss: 0.2121\n",
      "Epoch 67/100\n",
      "1231/1231 [==============================] - 1s 515us/step - loss: 0.1740 - val_loss: 0.2117\n",
      "Epoch 68/100\n",
      "1231/1231 [==============================] - 1s 598us/step - loss: 0.1731 - val_loss: 0.2115\n",
      "Epoch 69/100\n",
      "1231/1231 [==============================] - 1s 534us/step - loss: 0.1723 - val_loss: 0.2112\n",
      "Epoch 70/100\n",
      "1231/1231 [==============================] - 1s 539us/step - loss: 0.1715 - val_loss: 0.2109\n",
      "Epoch 71/100\n",
      "1231/1231 [==============================] - 1s 525us/step - loss: 0.1707 - val_loss: 0.2106\n",
      "Epoch 72/100\n",
      "1231/1231 [==============================] - 1s 553us/step - loss: 0.1699 - val_loss: 0.2103\n",
      "Epoch 73/100\n",
      "1231/1231 [==============================] - 1s 537us/step - loss: 0.1692 - val_loss: 0.2101\n",
      "Epoch 74/100\n",
      "1231/1231 [==============================] - 1s 505us/step - loss: 0.1684 - val_loss: 0.2098\n",
      "Epoch 75/100\n",
      "1231/1231 [==============================] - 1s 621us/step - loss: 0.1676 - val_loss: 0.2096TA: 0s - loss: 0\n",
      "Epoch 76/100\n",
      "1231/1231 [==============================] - 1s 581us/step - loss: 0.1668 - val_loss: 0.2093\n",
      "Epoch 77/100\n",
      "1231/1231 [==============================] - 1s 542us/step - loss: 0.1661 - val_loss: 0.2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1231/1231 [==============================] - 1s 555us/step - loss: 0.1653 - val_loss: 0.2089\n",
      "Epoch 79/100\n",
      "1231/1231 [==============================] - 1s 531us/step - loss: 0.1646 - val_loss: 0.2086\n",
      "Epoch 80/100\n",
      "1231/1231 [==============================] - 1s 563us/step - loss: 0.1639 - val_loss: 0.2084\n",
      "Epoch 81/100\n",
      "1231/1231 [==============================] - 1s 528us/step - loss: 0.1631 - val_loss: 0.2082\n",
      "Epoch 82/100\n",
      "1231/1231 [==============================] - 1s 504us/step - loss: 0.1624 - val_loss: 0.2080\n",
      "Epoch 83/100\n",
      "1231/1231 [==============================] - 1s 524us/step - loss: 0.1617 - val_loss: 0.2078\n",
      "Epoch 84/100\n",
      "1231/1231 [==============================] - 1s 501us/step - loss: 0.1610 - val_loss: 0.2076\n",
      "Epoch 85/100\n",
      "1231/1231 [==============================] - 1s 563us/step - loss: 0.1603 - val_loss: 0.2074\n",
      "Epoch 86/100\n",
      "1231/1231 [==============================] - 1s 531us/step - loss: 0.1596 - val_loss: 0.2072\n",
      "Epoch 87/100\n",
      "1231/1231 [==============================] - 1s 488us/step - loss: 0.1589 - val_loss: 0.2070\n",
      "Epoch 88/100\n",
      "1231/1231 [==============================] - 1s 524us/step - loss: 0.1582 - val_loss: 0.2068\n",
      "Epoch 89/100\n",
      "1231/1231 [==============================] - 1s 546us/step - loss: 0.1575 - val_loss: 0.2067\n",
      "Epoch 90/100\n",
      "1231/1231 [==============================] - 1s 581us/step - loss: 0.1568 - val_loss: 0.2065\n",
      "Epoch 91/100\n",
      "1231/1231 [==============================] - 1s 543us/step - loss: 0.1561 - val_loss: 0.2064\n",
      "Epoch 92/100\n",
      "1231/1231 [==============================] - 1s 563us/step - loss: 0.1555 - val_loss: 0.2063\n",
      "Epoch 93/100\n",
      "1231/1231 [==============================] - 1s 547us/step - loss: 0.1548 - val_loss: 0.2062\n",
      "Epoch 94/100\n",
      "1231/1231 [==============================] - 1s 501us/step - loss: 0.1541 - val_loss: 0.2061\n",
      "Epoch 95/100\n",
      "1231/1231 [==============================] - 1s 624us/step - loss: 0.1535 - val_loss: 0.2060\n",
      "Epoch 96/100\n",
      "1231/1231 [==============================] - 1s 609us/step - loss: 0.1528 - val_loss: 0.2060\n",
      "Epoch 97/100\n",
      "1231/1231 [==============================] - 1s 618us/step - loss: 0.1522 - val_loss: 0.2059\n",
      "Epoch 98/100\n",
      "1231/1231 [==============================] - 1s 663us/step - loss: 0.1516 - val_loss: 0.2058\n",
      "Epoch 99/100\n",
      "1231/1231 [==============================] - 1s 603us/step - loss: 0.1509 - val_loss: 0.2058\n",
      "Epoch 100/100\n",
      "1231/1231 [==============================] - 1s 547us/step - loss: 0.1503 - val_loss: 0.2057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training network 2 (include links)\n",
    "epochs = 100\n",
    "x_train_fingerprints = mibig_fingerprints\n",
    "x_train_families = mibig_families\n",
    "\n",
    "enc2 = simplified_family_model(x_train_fingerprints.values, x_train_families.values, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"G:\\\\Dev\\\\Data\\\\saved_spectrum_fingerprint_non_binary_model.h5\"\n",
    "enc1.save(filepath)\n",
    "\n",
    "filepath = \"G:\\\\Dev\\\\Data\\\\saved_fingerprint_families_non_binary_model.h5\"\n",
    "enc2.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[(0, 14, 0.94908815,   0. ) (1, 63, 0.72022382,   0. )\n",
      " (2,  7, 0.78388278,   1. ) (3, 12, 0.92982456,   0. )\n",
      " (4,  0, 0.        , 100. ) (5, 10, 0.9453125 ,   0. )\n",
      " (6, 91, 0.96663697,   0. ) (7, 23, 0.66553316,   0.2)]\n",
      "\n",
      "[[0.47112462 0.48575228 0.29141337 ... 0.54844225 0.54863222 0.46181611]\n",
      " [0.40459061 0.52095466 0.45512162 ... 0.47093754 0.45432226 0.43074112]\n",
      " [0.53333333 0.82234432 0.503663   ... 0.56446886 0.42161172 0.45164835]\n",
      " ...\n",
      " [0.503125   0.54661458 0.52239583 ... 0.45208333 0.44244792 0.54921875]\n",
      " [0.45990496 0.46930997 0.53895654 ... 0.46841897 0.45995446 0.4984655 ]\n",
      " [0.49392762 0.51165897 0.38559631 ... 0.59533641 0.49514209 0.44389118]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using linked mibig-gnps as test set\n",
    "x_train_spectra = load_master_file(path=test_datapath)\n",
    "predicted = enc1.predict(x_train_spectra)\n",
    "\n",
    "gnps_families_path = \"G:\\\\Dev\\\\Data\\\\gnps_family.txt\"\n",
    "x_train_families = load_families_master(gnps_families_path)\n",
    "x_train_fingerprints = load_fingerprints_master(test_fingerprint_path, number_of_rows=1)\n",
    "\n",
    "actual = x_train_families.values\n",
    "predicted = enc2.predict(x_train_fingerprints.values) # using true fingerprints\n",
    "#predicted = enc2.predict(predicted) # using predicted fingerprints\n",
    "exp_stats, exp_perm_scores = compute_auc(8, actual, predicted)\n",
    "\n",
    "print(exp_stats)\n",
    "print()\n",
    "print(exp_perm_scores)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[(0,  79, 0.97442822,  0.) (1, 482, 0.92773362,  0.)\n",
      " (2, 123, 0.97289973,  0.) (3,  68, 0.99029977,  0.)\n",
      " (4,   1, 0.12874909, 89.) (5,  98, 0.97739033,  0.)\n",
      " (6, 680, 0.94360251,  0.) (7, 176, 0.89642122,  0.)]\n",
      "\n",
      "[[0.45103161 0.47491923 0.50625055 ... 0.43845685 0.45707103 0.51158783]\n",
      " [0.49298446 0.48221528 0.50517501 ... 0.50236037 0.5334526  0.51648394]\n",
      " [0.47195938 0.51093153 0.4969602  ... 0.50802886 0.50460378 0.51072257]\n",
      " ...\n",
      " [0.49936928 0.50367186 0.48497509 ... 0.52834244 0.49127832 0.48041941]\n",
      " [0.48573337 0.48406186 0.51647786 ... 0.52916061 0.47950368 0.48519793]\n",
      " [0.51710742 0.51565837 0.50249056 ... 0.49715909 0.51307724 0.53203173]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using mibig all as test dataset\n",
    "x_train_fingerprints = mibig_fingerprints\n",
    "x_train_families = mibig_families\n",
    "\n",
    "actual = x_train_families.values\n",
    "predicted = enc2.predict(x_train_fingerprints.values) # using true fingerprints\n",
    "exp_stats, exp_perm_scores = compute_auc(8, actual, predicted)\n",
    "\n",
    "print(exp_stats)\n",
    "print()\n",
    "print(exp_perm_scores)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = [\"Alkaloid\", \"NRP\", \"Terpene\", \"RiPP\", \"Nucleoside\", \"Saccharide\", \"Polyketide\", \"Other\"]\n",
    "family_dict = {}\n",
    "family_counter_dict = {}\n",
    "family_missed_highest = {}\n",
    "mol_family_dict = {}\n",
    "\n",
    "for family in families:\n",
    "    family_dict[family] = 0\n",
    "    family_counter_dict[family] = 0\n",
    "    family_missed_highest[family] = 0\n",
    "    \n",
    "# with open(gnps_families_path, 'r') as f:\n",
    "with open(families_path, 'r') as f:\n",
    "    for line in f:\n",
    "        mol_id, family_index, value = line.split(\"  \")\n",
    "        family_dict[families[int(family_index)]] += 1\n",
    "        \n",
    "        if mol_id not in mol_family_dict:\n",
    "            mol_family_dict[mol_id] = {}\n",
    "            mol_family_dict[mol_id][\"families\"] = []\n",
    "            mol_family_dict[mol_id][\"probabilities\"] = []\n",
    "            \n",
    "        mol_family_dict[mol_id][\"families\"].append(families[int(family_index)])\n",
    "        \n",
    "print(family_dict)\n",
    "\n",
    "for index, probabilities in enumerate(predicted):\n",
    "    probabilities = list(probabilities)\n",
    "    mol_family_dict[x_train_families.index[index]][\"probabilities\"] = probabilities \n",
    "    true_labels = mol_family_dict[x_train_families.index[index]][\"families\"]\n",
    "    index_of_maximum = probabilities.index(max(probabilities))\n",
    "    if families[index_of_maximum] in true_labels:\n",
    "        family_counter_dict[families[index_of_maximum]] += 1\n",
    "\n",
    "for family in families:\n",
    "    for id, details in mol_family_dict.items():\n",
    "        index_of_maximum = details[\"probabilities\"].index(max(details[\"probabilities\"]))\n",
    "        if family not in details[\"families\"] and index_of_maximum == families.index(family):\n",
    "            family_missed_highest[family] += 1\n",
    "            \n",
    "print(family_counter_dict)\n",
    "print(family_dict)\n",
    "print(family_missed_highest)\n",
    "\n",
    "print(\"Family, proportion guessed correctly, proportion missed\")\n",
    "for family in family_dict:\n",
    "    if family_dict[family] == 0:\n",
    "        print(family, \"no sample\")\n",
    "    else:\n",
    "        print(family + \", \" + str(family_counter_dict[family]/family_dict[family] * 100) +\n",
    "             \", \" + str(family_missed_highest[family]/(1813-family_dict[family]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mibig_links_path = \"G:\\\\Dev\\\\Data\\\\mibig_gnps_links_q3_loose.csv\"\n",
    "mibig_family_path = \"G:\\\\Dev\\\\Data\\\\mibig_family\\\\gene_family.txt\"\n",
    "mibig_gnps_df = pd.read_csv(mibig_links_path, sep=\",\")\n",
    "\n",
    "mibig_gnps_dict = {}\n",
    "mibig_families = {}\n",
    "mibig_families_count = {}\n",
    "\n",
    "for index, row in mibig_gnps_df.iterrows():\n",
    "    if row[\"gnps_id\"] not in mibig_gnps_dict:\n",
    "        mibig_gnps_dict[row[\"gnps_id\"]] = set()\n",
    "    mibig_gnps_dict[row[\"gnps_id\"]].add(row[\"#mibig_id\"])\n",
    "\n",
    "with open(mibig_family_path, 'r') as f:\n",
    "    for line in f:\n",
    "        mibig_id, family = line.split(\"  \")\n",
    "        if mibig_id not in mibig_families:\n",
    "            mibig_families[mibig_id] = []\n",
    "        mibig_families[mibig_id].append(family[:-1])\n",
    "        \n",
    "probability_report_path = \"G:\\\\Dev\\\\Data\\\\gnps_prediction_report.csv\"\n",
    "families = [\"Alkaloid\", \"NRP\", \"Terpene\", \"RiPP\", \"Nucleoside\", \"Saccharide\", \"Polyketide\", \"Other\"]\n",
    "true_family_counter = {}\n",
    "family_correct_counter = {}\n",
    "\n",
    "for family in families:\n",
    "    true_family_counter[family] = 0\n",
    "    family_correct_counter[family] = 0\n",
    "\n",
    "with open(probability_report_path, 'w') as f:\n",
    "    f.write(\"#mibig_id,gnps_id,Alkaloid,NRP,Terpene,RiPP,Nucleoside,Saccharide,Polyketide,Other,True Label\\n\")\n",
    "\n",
    "with open(probability_report_path, 'a') as f:    \n",
    "    for index, probabilities in enumerate(predicted):\n",
    "        temp = copy.deepcopy(probabilities).tolist()\n",
    "        gnps_id = x_train_fingerprints.index[index]\n",
    "        prob_string = \",\".join(map(str, probabilities))\n",
    "        for mibig_id in mibig_gnps_dict[gnps_id]:\n",
    "            true_labels = []\n",
    "            max_indexes = []\n",
    "            for true_family in mibig_families[mibig_id]:\n",
    "                true_labels.append(true_family)\n",
    "                max_index = temp.index(max(temp))\n",
    "                max_indexes.append(max_index)\n",
    "                temp.remove(temp[max_index])\n",
    "                true_family_counter[true_family] += 1\n",
    "                f.write(mibig_id + \",\" + gnps_id + \",\" + prob_string + \",\" + true_family + \"\\n\")\n",
    "            for index in max_indexes:\n",
    "                if families[index] in true_labels:\n",
    "                    family_correct_counter[families[index]] += 1\n",
    "    \n",
    "prediction_comparison_report_path = \"G:\\\\Dev\\\\Data\\\\prediction_comparison_report.txt\"\n",
    "with open(prediction_comparison_report_path, 'w') as f:\n",
    "    f.write(\"family,matched,actual,proportion\\n\")\n",
    "\n",
    "with open(prediction_comparison_report_path, 'a') as f:\n",
    "    for family in family_correct_counter:\n",
    "        matched = family_correct_counter[family]\n",
    "        actual = true_family_counter[family]\n",
    "        proportion = 0\n",
    "        if actual != 0:\n",
    "            proportion = matched / actual\n",
    "        f.write(family + \",\" + str(matched) + \",\" + str(actual) + \",\" + str(proportion*100) + \"\\n\")\n",
    "    \n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

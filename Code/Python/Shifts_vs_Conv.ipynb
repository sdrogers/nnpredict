{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Notebook to play with convolution for networks\n",
    "\n",
    "- Setup a binary classification task\n",
    "- Have peak probabilities for each class\n",
    "- Then have some shifts also for the class and see if convolution can improve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_random_ones = None\n",
    "training_random_zeros = None\n",
    "test_random_ones = None\n",
    "test_random_zeros = None\n",
    "\n",
    "all_ones = None\n",
    "all_zeros = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_of_training_set(has_substructure_path):\n",
    "    global all_ones\n",
    "    global all_zeros\n",
    "    substructure = np.loadtxt(has_substructure_path, np.int)\n",
    "    all_ones = np.where(substructure == 1)\n",
    "    all_zeros = np.where(substructure == 0)\n",
    "\n",
    "    number_of_training_set = int(len(all_ones[0]) * 0.7)\n",
    "    return number_of_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_and_test_set(num_of_training_set):\n",
    "    global training_random_ones\n",
    "    global training_random_zeros\n",
    "    global test_random_ones\n",
    "    global test_random_zeros\n",
    "\n",
    "    training_random_ones = random.sample(list(all_ones[0]), num_of_training_set)\n",
    "    training_random_zeros = random.sample(list(all_zeros[0]), num_of_training_set)\n",
    "\n",
    "    test_random_ones = [ones for ones in all_ones[0] if ones not in training_random_ones]\n",
    "    test_random_zeros = [zeros for zeros in all_zeros[0] if zeros not in training_random_zeros]\n",
    "    test_random_zeros = random.sample(test_random_zeros, len(test_random_ones))\n",
    "    \n",
    "def get_list_of_ids(dataset):\n",
    "    return [\"GNPS_ALL_\" + str(index+1) for index in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset_dir = \"G:\\\\Dev\\\\Data\\\\MSMS-NIST\\\\Python Filtered\"\n",
    "\n",
    "def load_training_spec(spec_path):\n",
    "    global training_random_ones\n",
    "    global training_random_zeros\n",
    "    training_random_ones_id = get_list_of_ids(training_random_ones)\n",
    "    training_random_zeros_id = get_list_of_ids(training_random_zeros)\n",
    "    training_set = training_random_ones_id + training_random_zeros_id\n",
    "    \n",
    "    file_list = os.listdir(spec_path)\n",
    "    \n",
    "    filtered_file_list = [file for file in file_list if file[:-13] in training_set]\n",
    "    filtered_name_list = [filename[:-13] for filename in filtered_file_list]\n",
    "\n",
    "    intensities = pd.DataFrame(0.0, index = filtered_name_list, columns=range(1000), dtype=float)\n",
    "\n",
    "    for file in filtered_file_list:\n",
    "        filepath = os.path.join(filtered_dataset_dir, file)\n",
    "        mol_name = file[:-13]\n",
    "        with open(filepath, 'r') as f:\n",
    "            for index, line in enumerate(f):\n",
    "                mass, intensity = line.split(\" \")\n",
    "                if not math.isnan(float(intensity)):\n",
    "                    intensities.at[mol_name, int(mass)-1] = float(intensity)\n",
    "    \n",
    "    return intensities\n",
    "\n",
    "def load_test_spec(spec_path):\n",
    "    global test_random_ones\n",
    "    global test_random_zeros\n",
    "    test_random_ones_id = get_list_of_ids(test_random_ones)\n",
    "    test_random_zeros_id = get_list_of_ids(test_random_zeros)\n",
    "    test_set = test_random_ones_id + test_random_zeros_id\n",
    "    file_list = os.listdir(spec_path)\n",
    "    \n",
    "    filtered_file_list = [file for file in file_list if file[:-13] in test_set]\n",
    "    filtered_name_list = [filename[:-13] for filename in filtered_file_list]\n",
    "\n",
    "    test_intensities = pd.DataFrame(0.0, index = filtered_name_list, columns=range(1000), dtype=float)\n",
    "\n",
    "    for file in filtered_file_list:\n",
    "        filepath = os.path.join(filtered_dataset_dir, file)\n",
    "        mol_name = file[:-13]\n",
    "        with open(filepath, 'r') as f:\n",
    "            for index, line in enumerate(f):\n",
    "                mass, intensity = line.split(\" \")\n",
    "                if not math.isnan(float(intensity)):\n",
    "                    test_intensities.at[mol_name, int(mass)-1] = float(intensity)\n",
    "    \n",
    "    return test_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_has_substructure(content, intensities):\n",
    "    has_substructure_truth_values = []\n",
    "    for index in intensities.index:\n",
    "        has_substructure_truth_values.append(int(content[int(index.split('_')[2]) - 1][:-1]))\n",
    "        \n",
    "    return has_substructure_truth_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a simple keras model to classify this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model,Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import SGD\n",
    "def baseline_model(input_to_network):\n",
    "    class_model = Sequential()\n",
    "    class_model.add(Dense(50, input_dim=input_to_network.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    class_model.add(Dense(10,kernel_initializer='normal',activation = 'relu'))\n",
    "    class_model.add(Dense(1,kernel_initializer='normal',activation = 'sigmoid'))\n",
    "    class_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return class_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following model is a convolutional model for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods generate spectra that include these shifts and convert the data into the necessary tensor format\n",
    "\n",
    "- To generate a spectrum, we choose a number of peaks from a Poisson\n",
    "- We then sample a shift from the class-specific shift distribution\n",
    "- Sample a starting point\n",
    "- Sample an intensity for the start and end\n",
    "- Increment the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_spec_into_tensor(spec_array,shift=[10,20]):\n",
    "    n_spec,n_bins = spec_array.shape\n",
    "    spec_tensor = np.zeros((n_spec,n_bins,len(shift)+1),np.double)\n",
    "    for i in range(n_spec):\n",
    "        spec = spec_array[i,:]\n",
    "        shift_spec = np.copy(spec)\n",
    "        for s in shift:\n",
    "            shift_spec = np.vstack((shift_spec,np.hstack((spec[s:],np.zeros(s)))))\n",
    "        spec_tensor[i,:,:] = shift_spec.T\n",
    "    return spec_tensor[:,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(X,n_noise = 5000):\n",
    "    N,M = X.shape\n",
    "    for n in range(N):\n",
    "        X[n,:] += np.random.multinomial(np.random.poisson(n_noise),[1.0/M for m in range(M)])\n",
    "    return X\n",
    "def normalise(X):\n",
    "    for i,row in enumerate(X):\n",
    "        tot = row.sum()\n",
    "        if tot > 0:\n",
    "            for j in range(len(row)):\n",
    "                X[i,j] = (1.0*row[j])/tot\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate data for the two classes, add some noise and normalise\n",
    "- Note that `use_shifts` is what the model uses.\n",
    "- We don't need all the possible shifts to be in `use_shifts` as long as the kernel has sufficient width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Flatten,MaxPooling2D,AveragePooling2D\n",
    "def conv_model(n_bins = 1000, n_kernels = 2,kernel_width=1,use_shifts=[15]):\n",
    "    class_model = Sequential()\n",
    "    input_shape = (n_bins,len(use_shifts)+1,1)\n",
    "    n_kernels = n_kernels\n",
    "    \n",
    "    pool_width = n_bins - (kernel_width+1)\n",
    "    pool_size = (pool_width,1)\n",
    "    \n",
    "    kernel_size = (kernel_width,len(use_shifts)+1)\n",
    "    class_model.add(Conv2D(n_kernels, input_shape=input_shape, \n",
    "                           kernel_initializer='normal', activation='relu',strides=1,\n",
    "                          kernel_size = kernel_size))\n",
    "\n",
    "#     class_model.add(AveragePooling2D(pool_size = pool_size))\n",
    "    class_model.add(MaxPooling2D(pool_size = pool_size))\n",
    "    class_model.add(Flatten())\n",
    "    class_model.add(Dense(1,kernel_initializer='normal',activation = 'sigmoid'))\n",
    "    class_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return class_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_peak_differences(spec):\n",
    "    non_zero_peaks = list(np.where(spec>0)[0])\n",
    "    peak_differences = [(abs(i-j), (spec[i]+spec[j]/2.0)) for i in non_zero_peaks for j in non_zero_peaks if i != j and j > i]\n",
    "    \n",
    "    return peak_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shift_bins(intensities):\n",
    "    shift_bins = np.zeros(intensities.shape, np.double)\n",
    "\n",
    "    for index, spec in enumerate(intensities.values):\n",
    "        peak_differences = calc_peak_differences(spec)\n",
    "        for shift, average_intensity in peak_differences:\n",
    "            shift_bins[index, shift - 1] += average_intensity\n",
    "\n",
    "    return shift_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_diff_splits(path, name, has_substruct_dataset, shift, splits=10):\n",
    "    global filtered_dataset_dir\n",
    "    global training_random_ones\n",
    "    global training_random_zeros\n",
    "    global test_random_ones\n",
    "    global test_random_zeros\n",
    "    epochs = 200\n",
    "    extra_epochs = 100\n",
    "    path = path + name\n",
    "    n_kernels = 3\n",
    "    kernel_width = 5\n",
    "    truth_values = []\n",
    "    test_truth_values = []\n",
    "\n",
    "    with open(has_substruct_dataset, 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        for i in range(splits):\n",
    "            number_of_training_set = calculate_number_of_training_set(has_substruct_dataset)\n",
    "            build_training_and_test_set(number_of_training_set)\n",
    "\n",
    "            training_random_ones_id = get_list_of_ids(training_random_ones)\n",
    "            training_random_zeros_id = get_list_of_ids(training_random_zeros)\n",
    "            training_set = training_random_ones_id + training_random_zeros_id\n",
    "\n",
    "            test_random_ones_id = get_list_of_ids(test_random_ones)\n",
    "            test_random_zeros_id = get_list_of_ids(test_random_zeros)\n",
    "            test_set = test_random_ones_id + test_random_zeros_id\n",
    "            \n",
    "            intensities = load_training_spec(filtered_dataset_dir)\n",
    "            intensities = intensities.reindex(index=intensities.index.to_series().str.rsplit('_').str[-1].astype(int).sort_values().index)\n",
    "\n",
    "            test_intensities = load_test_spec(filtered_dataset_dir)\n",
    "            test_intensities = test_intensities.reindex(index=test_intensities.index.to_series().str.rsplit('_').str[-1].astype(int).sort_values().index)\n",
    "\n",
    "            truth_values = load_has_substructure(content, intensities)\n",
    "            test_truth_values = load_has_substructure(content, test_intensities)\n",
    "            \n",
    "            X = intensities.values\n",
    "            N,M = X.shape\n",
    "            shuffle_order = np.random.permutation(N)\n",
    "            labels = truth_values\n",
    "            labels = np.array(labels)[:,None]\n",
    "            test_labels = test_truth_values\n",
    "            test_labels = np.array(test_labels)[:,None]\n",
    "            \n",
    "            use_shifts = np.asarray([shift])\n",
    "\n",
    "            X_tensor = shift_spec_into_tensor(X,shift=use_shifts)\n",
    "            print(X_tensor.shape)\n",
    "            \n",
    "            mod = conv_model(n_kernels = n_kernels, kernel_width=kernel_width, use_shifts=use_shifts)\n",
    "            mod.fit(X_tensor[shuffle_order,:,:],labels[shuffle_order],epochs=epochs,validation_split=0.2,verbose=0)\n",
    "            \n",
    "            test_tensor = shift_spec_into_tensor(test_intensities.values,shift=use_shifts)\n",
    "            predicted = mod.predict(test_tensor)\n",
    "            \n",
    "            auc = roc_auc_score(test_labels, predicted)\n",
    "            f.write(str(auc) + \"\\n\")\n",
    "        \n",
    "def train_shifts_diff_splits(path, name, has_substruct_dataset, splits=10):\n",
    "    global filtered_dataset_dir\n",
    "    global training_random_ones\n",
    "    global training_random_zeros\n",
    "    global test_random_ones\n",
    "    global test_random_zeros\n",
    "    epochs = 200\n",
    "    extra_epochs = 100\n",
    "    path = path + name\n",
    "    truth_values = []\n",
    "    test_truth_values = []\n",
    "\n",
    "    with open(has_substruct_dataset, 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        for i in range(splits):\n",
    "            number_of_training_set = calculate_number_of_training_set(has_substruct_dataset)\n",
    "            build_training_and_test_set(number_of_training_set)\n",
    "\n",
    "            training_random_ones_id = get_list_of_ids(training_random_ones)\n",
    "            training_random_zeros_id = get_list_of_ids(training_random_zeros)\n",
    "            training_set = training_random_ones_id + training_random_zeros_id\n",
    "\n",
    "            test_random_ones_id = get_list_of_ids(test_random_ones)\n",
    "            test_random_zeros_id = get_list_of_ids(test_random_zeros)\n",
    "            test_set = test_random_ones_id + test_random_zeros_id\n",
    "\n",
    "            intensities = load_training_spec(filtered_dataset_dir)\n",
    "            intensities = intensities.reindex(index=intensities.index.to_series().str.rsplit('_').str[-1].astype(int).sort_values().index)\n",
    "           \n",
    "            test_intensities = load_test_spec(filtered_dataset_dir)\n",
    "            test_intensities = test_intensities.reindex(index=test_intensities.index.to_series().str.rsplit('_').str[-1].astype(int).sort_values().index)\n",
    "\n",
    "            truth_values = load_has_substructure(content, intensities)\n",
    "            test_truth_values = load_has_substructure(content, test_intensities)\n",
    "\n",
    "            X = intensities.values\n",
    "            N,M = X.shape\n",
    "            shuffle_order = np.random.permutation(N)\n",
    "            labels = truth_values\n",
    "            labels = np.array(labels)[:,None]\n",
    "            test_labels = test_truth_values\n",
    "            test_labels = np.array(test_labels)[:,None]\n",
    "\n",
    "            shift_bins = load_shift_bins(intensities)\n",
    "\n",
    "            X_shifts = normalise(shift_bins)\n",
    "            print(X_shifts.shape)\n",
    "\n",
    "            mod = baseline_model(X_shifts)\n",
    "            mod.fit(X_shifts[shuffle_order,:],labels[shuffle_order],epochs=extra_epochs,validation_split=0.2,verbose=0)\n",
    "\n",
    "            test_shift_bins = load_shift_bins(test_intensities)\n",
    "            X_test_shifts = normalise(test_shift_bins)\n",
    "            print(X_test_shifts.shape)\n",
    "\n",
    "            predicted = mod.predict(X_test_shifts)\n",
    "\n",
    "            auc = roc_auc_score(test_labels, predicted)\n",
    "            f.write(str(auc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alanine', 71), ('Arginine', 156), ('Asparagine', 114), ('Aspartic Acid', 115), ('Cysteine', 103), ('Glutamic Acid', 129), ('Glutamine', 128), ('Glycine', 57), ('Histidine', 137), ('Isoleucine', 113), ('Leucine', 113), ('Lysine', 128), ('Methionine', 131), ('Phenylalanine', 147), ('Proline', 97), ('Serine', 87), ('Threonine', 101), ('Tryptophan', 186), ('Tyrosine', 163), ('Valine', 99)]\n"
     ]
    }
   ],
   "source": [
    "amino_acid_path = \"G:\\\\Dev\\\\Data\\\\Fragment Masses.txt\"\n",
    "amino_acids_with_shifts = []\n",
    "\n",
    "with open(amino_acid_path, 'r') as f:\n",
    "    for line in f:\n",
    "        amino_acid, shift = line.split(\", \")\n",
    "        amino_acids_with_shifts.append((amino_acid, int(float(shift[:-1]))))\n",
    "\n",
    "print(amino_acids_with_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000)\n",
      "(1260, 1000)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(2934, 1000, 2, 1)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000)\n",
      "(324, 1000)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(750, 1000, 2, 1)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000)\n",
      "(330, 1000)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(764, 1000, 2, 1)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000)\n",
      "(376, 1000)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(872, 1000, 2, 1)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000)\n",
      "(264, 1000)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(610, 1000, 2, 1)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000)\n",
      "(276, 1000)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(644, 1000, 2, 1)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000)\n",
      "(302, 1000)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(702, 1000, 2, 1)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000)\n",
      "(314, 1000)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(728, 1000, 2, 1)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000)\n",
      "(308, 1000)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n",
      "(716, 1000, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "processed_amino_acid = [\"Alanine\", \"Arginine\", \"Glutamine\", \"Asparagine\", \"Aspartic Acid\", \"Cysteine\", \"Glutamic Acid\", \n",
    "                        \"Glycine\", \"Histidine\", \"Isoleucine\", \"Leucine\"]\n",
    "missing_amino_acid = \"Glutamine\"\n",
    "path = \"G:\\\\Dev\\\\Data\\\\Convolution vs Dense Experiments corrected\\\\\"\n",
    "\n",
    "for amino_acid, shift in amino_acids_with_shifts:\n",
    "    if amino_acid != missing_amino_acid and amino_acid not in processed_amino_acid:\n",
    "        dataset = \"G:\\\\Dev\\\\Data\\\\NIST Amino Acids\\\\NIST {} Has Substructure.txt\".format(amino_acid)\n",
    "        train_shifts_diff_splits(path, \"Shifts {} AUC.txt\".format(amino_acid), dataset)\n",
    "        train_conv_diff_splits(path, \"Conv {} AUC.txt\".format(amino_acid), dataset, shift, splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Shifts', 'Conv'], dtype='object')\n",
      "          0\n",
      "0  0.852761\n",
      "1  0.820384\n",
      "2  0.821391\n",
      "3  0.899595\n",
      "4  0.844519\n",
      "5  0.840184\n",
      "6  0.890185\n",
      "7  0.903554\n",
      "8  0.848412\n",
      "9  0.888131\n",
      "          0\n",
      "0  0.714301\n",
      "1  0.588177\n",
      "2  0.669562\n",
      "3  0.677857\n",
      "4  0.663588\n",
      "5  0.691817\n",
      "6  0.653387\n",
      "7  0.689710\n",
      "8  0.677173\n",
      "9  0.560512\n",
      "     Shifts      Conv\n",
      "0  0.852761  0.714301\n",
      "1  0.820384  0.588177\n",
      "2  0.821391  0.669562\n",
      "3  0.899595  0.677857\n",
      "4  0.844519  0.663588\n",
      "5  0.840184  0.691817\n",
      "6  0.890185  0.653387\n",
      "7  0.903554  0.689710\n",
      "8  0.848412  0.677173\n",
      "9  0.888131  0.560512\n"
     ]
    }
   ],
   "source": [
    "path = \"G:\\\\Dev\\\\Data\\\\Convolution vs Dense Experiments corrected\\\\\"\n",
    "df_shifts = pd.read_csv(path + \"Shifts Alanine AUC.txt\", header=None)\n",
    "df_conv = pd.read_csv(path + \"Conv Alanine AUC.txt\", header=None)\n",
    "df_combined = pd.concat([df_shifts, df_conv], axis=1)\n",
    "df_combined.columns = [\"Shifts\", \"Conv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=11.221065799556373, pvalue=1.360958273920665e-06)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(df_combined['Shifts'], df_combined['Conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alanine: Ttest_relResult(statistic=11.221065799556373, pvalue=1.360958273920665e-06)\n",
      "Arginine: Ttest_relResult(statistic=28.5750086111355, pvalue=3.8328019853930337e-10)\n",
      "Asparagine: Ttest_relResult(statistic=16.725438280769435, pvalue=4.36717980880867e-08)\n",
      "Aspartic Acid: Ttest_relResult(statistic=10.596471853565722, pvalue=2.20475016639447e-06)\n",
      "Cysteine: Ttest_relResult(statistic=20.999878665699455, pvalue=5.902295392507168e-09)\n",
      "Glutamic Acid: Ttest_relResult(statistic=16.11574726396528, pvalue=6.04057600384934e-08)\n",
      "Glycine: Ttest_relResult(statistic=21.29469907408046, pvalue=5.21802415846084e-09)\n",
      "Histidine: Ttest_relResult(statistic=24.686189478071988, pvalue=1.4084292165671842e-09)\n",
      "Isoleucine: Ttest_relResult(statistic=22.404763799156985, pvalue=3.3283701743627767e-09)\n",
      "Leucine: Ttest_relResult(statistic=23.173613772424893, pvalue=2.468281924435496e-09)\n",
      "Lysine: Ttest_relResult(statistic=17.375865382206925, pvalue=3.127198069649469e-08)\n",
      "Methionine: Ttest_relResult(statistic=15.327817324443428, pvalue=9.348512085218057e-08)\n",
      "Phenylalanine: Ttest_relResult(statistic=26.276007564751552, pvalue=8.08769109802662e-10)\n",
      "Proline: Ttest_relResult(statistic=25.627502344919723, pvalue=1.0100222289747276e-09)\n",
      "Serine: Ttest_relResult(statistic=12.40721886217737, pvalue=5.791774484541126e-07)\n",
      "Threonine: Ttest_relResult(statistic=16.519758319259353, pvalue=4.866063644398779e-08)\n",
      "Tryptophan: Ttest_relResult(statistic=14.258275934854591, pvalue=1.7509872047212962e-07)\n",
      "Tyrosine: Ttest_relResult(statistic=14.81830887140648, pvalue=1.2539952191166017e-07)\n",
      "Valine: Ttest_relResult(statistic=21.626969016103633, pvalue=4.550337194863764e-09)\n"
     ]
    }
   ],
   "source": [
    "path = \"G:\\\\Dev\\\\Data\\\\Convolution vs Dense Experiments corrected\\\\\"\n",
    "missing_amino_acid = \"Glutamine\"\n",
    "\n",
    "for amino_acid, shift in amino_acids_with_shifts:\n",
    "    if amino_acid != missing_amino_acid:        \n",
    "        df_shifts = pd.read_csv(path + \"Shifts {} AUC.txt\".format(amino_acid), header=None)\n",
    "        df_conv = pd.read_csv(path + \"Conv {} AUC.txt\".format(amino_acid), header=None)\n",
    "        df_combined = pd.concat([df_shifts, df_conv], axis=1)\n",
    "        df_combined.columns = [\"Shifts\", \"Conv\"]\n",
    "        t_test = stats.ttest_rel(df_combined['Shifts'], df_combined['Conv'])\n",
    "        print(amino_acid + \": \" + str(t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alanine', 'Arginine', 'Asparagine', 'Aspartic Acid', 'Cysteine', 'Glutamic Acid', 'Glycine', 'Histidine', 'Isoleucine', 'Leucine', 'Lysine', 'Methionine', 'Phenylalanine', 'Proline', 'Serine', 'Threonine', 'Tryptophan', 'Tyrosine', 'Valine']\n"
     ]
    }
   ],
   "source": [
    "path = \"G:\\\\Dev\\\\Data\\\\Convolution vs Dense Experiments corrected\\\\\"\n",
    "nist_baseline_auc_path = \"G:\\\\Dev\\\\Data\\\\NIST Amino Acids\\\\NIST Baseline AUC.txt\"\n",
    "missing_amino_acid = \"Glutamine\"\n",
    "\n",
    "baseline_aucs = {}\n",
    "average_auc_scores = []\n",
    "baseline_auc_scores = []\n",
    "\n",
    "with open(nist_baseline_auc_path, 'r') as f:\n",
    "    for line in f:\n",
    "        amino_acid, baseline_auc = line.split(\",\")\n",
    "        baseline_aucs[amino_acid] = float(baseline_auc[:-1])\n",
    "\n",
    "for amino_acid, shift in amino_acids_with_shifts:\n",
    "    if amino_acid != missing_amino_acid:\n",
    "        auc_scores = np.loadtxt(path + \"Shifts {} AUC.txt\".format(amino_acid), np.float32)\n",
    "        average_auc = np.mean(auc_scores)\n",
    "        baseline_auc = baseline_aucs[amino_acid]\n",
    "        average_auc_scores.append(average_auc)\n",
    "        baseline_auc_scores.append(baseline_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23a12db7be0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAE7CAYAAAAB2IJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmYFOW5/vHvLUIAwR0TFRGiYgIIyCZGEzEq7qhHjbhrEk1y3HM0btHj0ZPkF5NzcsUlblGzqIhiUJJwJBLEFZVFYthUggvjCkRRCNvg8/uj3oGmmaWHmaaGmftzXX1Nbf30U1U9/dT7VnW1IgIzMzPLx2Z5J2BmZtaSuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM0amaQhkioKxmdKGpJjSmbWhLkQW9lJelPSB5K2KJj2bUkTC8ZD0u5peGtJ90h6X9Knkl6TdLmkLpKWFDxC0tKC8a9W89oTJS1P8xdLelrSXhtlxZOI6BkRE8sVX9J1aVsMqmb6fdUsv2Zbp/FD03b5VNICSU9JGlaufAted4u0X8aW+7U2JmXmSZpVzbw3JR1cNO0sSc8WjLdJ++719P5+M/0/dC1/9pYHF2LbWDYHLipx2V8AHYAvA1sBw4B/RMTbEdGh6pGW7VMw7Zka4p2flt8OmAj8foPXoomRJOB04J/AmRvw/BOAh4HfAZ2BzwPXAkc3Ypo1OQFYAQyVtGM5XkDS5uWIW4evATsAX5Q0cAOeP4rsPX8K2fu/DzAVOKjRMrQmxYXYNpafAZdK2rqEZQcCD0TERxHxWUTMiYhRDU0gIiqBB4EeVdMkDZI0SdLHkt6TdIukNmmeJP1C0oepNf2KpF5p3uck/VzS26m1f7ukdtW9bmErKLV0HpL0u9QCnSlpQMGyO0l6JLVM35B0YR2r9VVgJ7KDnOFVuZciFfH/BW6IiF9HxOK0vZ+KiHOqWX4nScskbVswbW9JCyW1lrR7ak0vTtNG1pHCmcDtwCvAqQUxr5C0zv6W9EtJN6XhrSTdnfbXO5L+W1KrNO8sSc+l/fZP4DpJu0maIGlRyuv+wvehpH6SXk7742FJIyX9d8H8oyRNT++R5yX1LmG9HgPGUs+Do/Q+OQQ4JiImR0Rl2i+3RsTd9Yllmw4XYttYppC1Ri8tYdkXgB9JOlvSHo2VQCpSp6b4VVYDlwDbA/uStTr+Pc0bSta66Q5sDZwELErzfpqm9wV2B3Yma0mWYhjZAcHWwBjglpTfZsAfgb+leAcBF0s6tJZYZ6bnVBW9o0rMAWBPYBeyFlidIuJdYBJwfMHkU4BREbEKuAH4C7ANWev65ppiSeoCDAHuT48zCmaPAI6QtGVathXwDeCBNP+3QCXZdt+bbD99u+D5+wDzyFqlPwIE/ITsgOXLaZ2vS7HbAKOB3wDbptc+riDPfsA9wHfIelTuAMZI+lwN69WerKVftV71OjgCDgZeioj59XiObeJciG1juha4QFKnOpa7gOxD7HxglqS5kg5vwOveJOljYEmK+V9VMyJiakS8kFoeb5J90B6QZq8COgJfAhQRsyPivdSSPAe4JCL+GRGfAj8GhpeYz7MRMTYiVpN1k/dJ0wcCnSLi+ohYGRHzgLtqips+9E8k6z1YRVZQ69MC2y79fa8ez3kAODm9vlJuVQVyFbArsFNELI+IZ6sPAWSF95WImEVW/HpK2hsgIt4CpgHHpmW/DvwrIl6Q9HngcODiiFgaER+Sncoo3EbvRsTNaZ8ui4i5EfFERKyIiAVkvQBV+3gw2WmTmyJiVUT8AXipINY5wB0R8WJErI6I35J1pw+uYb3+Lc3/C/CnFPvIWrZDse2o3/6wZsCF2DaaiJhB9uF0RR3LLYuIH0dEf7IPpoeAhwu7ROvpwojYGmhL1mIcVdW9KKm7pD8puzDsE7KCun3KYwJZa/VW4ANJd6ZWWiegPTA1dVd+DDyeppfi/YLhfwFt07nMXYGdqmKmuFeRnbetznFkLcOqi53uBw4vONCpBFoXPkFS1fgq1rbu63N+dhSwr6SdyHoLAqg6N/8DstbnS6nL/Zu1xDkj5VvV0n6KdQ8i1hR8slZ3VbHfNa3TewXb6A6y1m+VdVqTknaQ9GDqxv4EuI+0j8laye/Eur9+U/j8XYH/KNonu6TnVedM4KF0ELAC+EPReq23T9L4qjS8iPrtD2sGXIhtY/tPslbGzqUsHBFVxXELoFtDXjid/3wGmEvWnQlwGzAH2CMitiQrfCp4zk3pgKAnWVf0ZcBCYBnQMyK2To+tCi4g21DzgTcKYm4dER0j4ogalj+T7KK2tyW9T3bRVWvWFrC3ga5Fz+lG1h3/DvBqes3jKVFEfEzW2vsGWYEcUVXEIuL9iDgnInYi68r9lQquzq4i6SvAHsCV6QDofbLu5JO19uKqh4EhkjqTHXBUFeL5ZC3O7Qu20ZYR0bMwzaKX/Ema1jvt49NYu4/fA3ZOrfsquxQMzwd+VLRP2kfEiGrWqzNZ6/20gvU6gaybvarw17RP3krD44FBKZa1EC7EtlFFxFyy85k1XoQk6RpJA5V9jaMt2YVIH5MVjgaRtC/ZxVoz06SOwCfAEklfAr5XsOxASfukVuRSYDmwOiI+I+sy/oWkHdKyO9dxLrcULwGfKPuqVjtJrST1UjVX3kqqOod8FNl56r5kXdw/ZW0L7HFgT0mnp4uptiU7qBmVWmwBfB+4Jp2P31LSZpL2l3RnLXk+QNaiPZ61BRJJJxYUkI/Iit/qap5/JvAE2X6oyr0XWS/D4QCpC3kicC/ZwcnsNP09sgOB/ynIdzdJB6z3Kmt1JDst8XHabpcVzJuUcjxf0uaSjgEKvwZ2F/Dd9D6Qsq9cHSmpYzWvczrwGtm596r16g5UsPbgaCTZef8vpXgDgG+SXTNARIxP22a0pP4pp46SvltHD4NtyiLCDz/K+gDeBA4uGN+FrKhNLJgWwO5p+IfADLIC+U+yD+SvVBN3zXNqee2J6bWWpMdcsnO7VfO/RtYiXkLWxXo92TlcyArdK2neQrKu1A5pXluyojYv5TmbrAscsouQKqpbf7KLhO4rmNc1rcfmaXwnsnOm75MVsxcKt13B864AplYzfSeybs5eafwrwLMp1rvA3cA2Rc85LK37EqCqAB5ZyzZtB3wKzCyafiNZS3sJ8A/g3Gqe2zblcnQ1835FdpBQNX562jaXFS23FVlPRgWwGHgZGJ7mnVW1/wqW70n29Z8lwHTgP4r2z4A0fQlZS/wPwDVF22cy2cHge2mZjtXkPwe4oJrpPwCmpOHN0r57Pb1vZgHfKlq+Ddl1DHPJDgDfAn4NdMn7f9mP8jyUdryZmQGSXgRuj4h7887FWgZ3TZtZiybpAElfSN3AZwK9ybr1zTaKPO46Y2bWlOxJdmV+B7Iu9RMiOxdttlG4a9rMzCxH7po2MzPLkQuxmZlZjja5c8Tbb799dO3aNe80zMzMajV16tSFEVHnHfc2uULctWtXpkyZkncaZmZmtZL0Vt1LuWvazMwsVy7EZmZmOXIhNjMzy9Emd464OqtWraKiooLly5fnncompW3btnTu3JnWrYt/lc3MzDaWZlGIKyoq6NixI127dmXdXzOzmkQEixYtoqKigm7dGvTrgmZm1gDNomt6+fLlbLfddi7C9SCJ7bbbzr0IZmY5axaFGHAR3gDeZmZm+Ws2hThvrVq1om/fvvTp04d+/frx/PPPN2r8s846i1GjRgHw7W9/m1mzZjVqfDMzy0ezOEdcrLEbeqX8Lka7du2YPn06AOPGjePKK6/kqaeeatxEkl//+tdliWtmZhufW8Rl8Mknn7DNNtsAsGTJEg466CD69evHXnvtxWOPPQbA0qVLOfLII+nTpw+9evVi5MiRAEydOpUDDjiA/v37c+ihh/Lee+v/GtuQIUPW3F2sQ4cOXH311fTp04fBgwfzwQcfALBgwQKOP/54Bg4cyMCBA3nuuec2xqqbmVk9NcsWcR6WLVtG3759Wb58Oe+99x4TJkwAsq8IjR49mi233JKFCxcyePBghg0bxuOPP85OO+3En//8ZwAWL17MqlWruOCCC3jsscfo1KkTI0eO5Oqrr+aee+6p8XWXLl3K4MGD+dGPfsQPfvAD7rrrLn74wx9y0UUXcckll7D//vvz9ttvc+ihhzJ79uyNsi3MzKx0LsSNpLBretKkSZxxxhnMmDGDiOCqq67i6XHj2EzinYoKPhg3jr2AS8eP5/LLL+eoo47iq1/9KjNmzGDGjBkccsghAKxevZodd9yx1tdt06YNRx11FAD9+/fniSeeAGD8+PHrnEf+5JNP+PTTT+nYsWMZ1t7MzDaUC3EZ7LvvvixcuJAFCxYwduxYFixYwNTf/57Wm29O12HDWL5yJd133ZWpU6cyduxYrrzySoYOHcpxxx1Hz549mTRpUsmv1bp16zVXP7dq1YrKykoAPvvsMyZNmkS7du3Kso5mdaruYo1SLrgwa2F8jrgM5syZw+rVq9luu+1YvHgxO+ywA60335wnp0zhrXTO990FC2jfvj2nnXYal156KdOmTWPPPfdkwYIFawrxqlWrmDlz5gblMHToUG655ZY141WtdTMza1rcIm4kVeeIIbtr1W9/+1tatWrFqaeeytFHH82Av/6Vvt2786X0W8p/nzuXyy6/nM0224zWrVtz22230aZNG0aNGsWFF17I4sWLqays5OKLL6Znz571zuemm27ivPPOo3fv3lRWVvK1r32N22+/vTFX2czMGoFiE+sqGjBgQBT/HvHs2bP58pe/nFNGJaruN5QHDNj4eRTZJLadbZrcNW0tnKSpEVHnB71bxGbWsvmAwXLmQmxmmw4XTWuGXIjNysmFw8zq4KumzczMcuQWsdmmxq1ss2bFhdjW5Q95M7ONyl3TjWj06NFIYs6cOXmn0rRI6z/MmrNN5T2/qeRZDk1o3ZtnIa5uAzfkUaIRI0aw//778+CDDzZ4FVavXt3gGGZmzUITKprl0DwLcQ6WLFnCc889x913372mEJ900kmMHTt2zTJnXXcdj0yYwOrVq7nsl79k4MCB9O7dmzvuuAOAiRMncuCBB3LKKaew1157AXDsscfSv39/evbsyZ133rkm1t1330337t0ZMmQI55xzDueffz7gnz80a7aaeTFqyXyOuJE8+uijHHbYYXTv3p1tt92WadOmMXz4cEaOHMkRRxzBylWr+Ovkydx2xRXc/dhjbNWhA5MnT2bFihXst99+DB06FICXXnqJGTNm0K1bNwDuuecett12W5YtW8bAgQM5/vjjWbFiBTfccAPTpk2jY8eOfP3rX6dPnz4A/vlDM7NNjAtxIxkxYgQXX3wxAMOHD2fEiBHccMMNXHjhhaxYsYLHn3+er+29N+3atuUvL77IK3PnMirdm3rx4sW8/vrrtGnThkGDBq0pwpDdM3r06NEAzJ8/n9dff53333+fAw44gG233RaAE088kddeew3wzx+amW1qXIgbwaJFi5gwYQIzZsxAEqtXr0YSN954I0OGDGHcuHGMfOIJTk6t3ojg5ksv5dALLlgnzsSJE9liiy3WGR8/fjyTJk2iffv2DBkyhOXLl7Pm/uBV969++2348EOYMqXl/Pyhr+5uXN6e1lj8Xqo3nyNuBKNGjeKMM87grbfe4s0332T+/Pl069aNZ599luHDh3PvvffyzMsvc+i++wJw6ODB3PbII6xatQqA1157jaVLl64Xd/HixWyzzTa0b9+eOXPm8MILLwAwaNAgnnrqKT765BMqKyt5ZMKENc/xzx+amW1aXIgbwYgRIzjuuOPWmXb88cfzwAMPMHToUJ5++mkOHjSINq1bA/DtY4+lR7du9OvXj169evGd73yHysrK9eIedthhVFZW0rt3b6655hoGDx4MwM4778xVV13FPmefzcHnnUePL36RrTp0ALKu7ClTptC7d2969Ojhnz40M2vi/DOI1SnHTxY2cswlS5bQYc4cKisrOe6yy/jmsGEcd+CB9Y653rYrR7fSphKzHDaVdXdMx3TMRv8M8c8gNnPXXXcd48eMYfnKlQwdPJhjhwzJOyUzM9sALsSbqJ///OcwfHjeaZiZWQP5HLGZmVmOmk0h3tTOdTcF3mZmZvlrFoW4bdu2LFq0yIWlHiKCRYsW0bZt27xTaTp8C0Ezy0GzOEfcuXNnKioqWLBgQeMEXLhw/WkNvU1kE4zZtm1bOnfu3LAczMysQZpFIW7duvU6t4VssB491p/W0Nb2phLTzMw2qmbRNW1mZrapciE2MzPLkQuxmZlZjlyIzczMcuRCbGZmlqOyFmJJh0l6VdJcSVdUM7+LpCclvSzpFUlHlDMfMzOzpqZshVhSK+BW4HCgB3CypOLv2/wQeCgi9gaGA78qVz5mZmZNUTlbxIOAuRExLyJWAg8CxxQtE8CWaXgr4N0y5mNmZtbklLMQ7wzMLxivSNMKXQecJqkCGAtcUF0gSedKmiJpSqPdPcvMzKwJKGchru5GvcW3fToZ+E1EdAaOAH4vab2cIuLOiBgQEQM6depUhlTNzMzyUc5CXAHsUjDemfW7nr8FPAQQEZOAtsD2ZczJzMysSSlnIZ4M7CGpm6Q2ZBdjjSla5m3gIABJXyYrxO57NjOzFqNshTgiKoHzgXHAbLKro2dKul7SsLTYfwDnSPobMAI4K/xbhmZm1oKU9deXImIs2UVYhdOuLRieBexXzhzqUt1PzvpIwMzMNpZm8TOIZmbNiRsILYsLsVkT5g9ks+bP95o2MzPLkQuxmZlZjlyIzczMcuRCbGZmliNfrNWC+UIgM7P8uUVsZmaWI7eIzazFcC9Qy9TU97tbxGZmZjlyi9gaVVM/8jQza2rcIjYzM8uRW8SbiJbc0mzJ627WWPx/1HS5EJuZNYALnDWUC7GZmTUZLfHAxueIzczMcuQWsbVILfGou0pLXnezpsiF2MyaJB8wWEvhrmkzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYj39DDrJH4BhRmtiHcIjYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHPmqaTMz2yD+pkDjcIvYzMwsRy7EZmZmOXIhNjMzy5HPEZtZg/lcodmGc4vYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlqKyFWNJhkl6VNFfSFTUs8w1JsyTNlPRAOfMxMzNrasp2Zy1JrYBbgUOACmCypDERMatgmT2AK4H9IuIjSTuUKx8zM7OmqJwt4kHA3IiYFxErgQeBY4qWOQe4NSI+AoiID8uYj5mZWZNTzkK8MzC/YLwiTSvUHegu6TlJL0g6rIz5mJmZNTnl/NGHam4Dv9594DcH9gCGAJ2BZyT1ioiP1wkknQucC9ClS5fGz9TMzCwn5WwRVwC7FIx3Bt6tZpnHImJVRLwBvEpWmNcREXdGxICIGNCpU6eyJWxmZraxlbMQTwb2kNRNUhtgODCmaJlHgQMBJG1P1lU9r4w5mZmZNSllK8QRUQmcD4wDZgMPRcRMSddLGpYWGwcskjQLeBK4LCIWlSunjUVa/2FmZladOs8RS7oR+G9gGfA40Ae4OCLuq+u5ETEWGFs07dqC4QC+nx5mZmYtTikt4qER8QlwFNk53e7AZWXNyszMrIUopRC3Tn+PAEZExD/LmI+ZmVmLUsrXl/4oaQ5Z1/S/S+oELC9vWmZmZi1DnS3iiLgC2BcYEBGrgH+x/h2yzMzMbAPUWYgltQfOA25Lk3YCBpQzKTMzs5ailHPE9wIrga+k8Qqyq6jNzMysgUopxLtFxI3AKoCIWEb1t680MzOzeiqlEK+U1I50n2hJuwErypqVmZlZC1HKVdP/SXYjj10k3Q/sB5xVzqTMzMxailoLsSQBc4B/AwaTdUlfFBELN0JuZmZmzV6thTgiQtKjEdEf+PNGysnMzKzFKOUc8QuSBpY9EzMzsxaolHPEBwLfkfQWsJSsezoiondZMzMzM2sBSinEh5c9CzMzsxaqlFtcvgVsDRydHlunaWZmZtZApdzi8iLgfmCH9LhP0gXlTszMzKwlKKVr+lvAPhGxFEDST4FJwM3lTMzMzKwlKOWqaQGrC8ZX41tcmpmZNYpSWsT3Ai9KGp3GjwXuLl9KZmZmLUedhTgi/lfSRGB/spbw2RHxcrkTMzMzawnqLMSSBgMzI2JaGu8oaZ+IeLHs2ZmZmTVzpZwjvg1YUjC+NE0zMzOzBirpYq2IiKqRiPiM0s4tm5mZWR1KKcTzJF0oqXV6XATMK3diZmZmLUEphfi7wFeAd9JjH+DcciZlZmbWUpRy1fSHwPCNkIuZmVmLU2OLWNI5kvZIw5J0j6TFkl6R1G/jpWhmZtZ81dY1fRHwZho+GegDfBH4PvDL8qZlZmbWMtRWiCsjYlUaPgr4XUQsiojxwBblT83MzKz5q60QfyZpR0ltgYOA8QXz2pU3LTMzs5ahtou1rgWmAK2AMRExE0DSAfjrS2ZmZo2ixkIcEX+StCvQMSI+Kpg1BTip7JmZmZm1ALV+fSkiKoGPiqYtLWtGZmZmLUgpN/QwMzOzMnEhNjMzy1FtN/Q4VNIJ1Uw/VdIh5U3LzMysZaitRfxfwFPVTP8rcH150jEzM2tZaivE7SNiQfHEiHgf39DDzMysUdRWiNtKWu+qakmt8Q09zMzMGkVthfgPwF2S1rR+0/DtaZ6ZmZk1UG2F+IfAB8BbkqZKmkb2IxAL0jwzMzNroNrurFUJXCHpv4Dd0+S5EbFso2RmZmbWAtRYiCX9W9GkALaWND0iPi1vWmZmZi1Dbbe4PLqaadsCvSV9KyImlCknMzOzFqO2rumzq5uefgjiIWCfciVlZmbWUtT7FpcR8RbQugy5mJmZtTj1LsSS9gRWlLjsYZJelTRX0hW1LHeCpJA0oL75mJmZbcpqu1jrj2QXaBXaFtgROL2uwJJaAbcChwAVwGRJYyJiVtFyHYELgRfrl7qZmdmmr7aLtX5eNB7AIuD1iFhZQuxBZF93mgcg6UHgGGBW0XI3ADcCl5aUsZmZWTNS28Va1f3gA5L2k3RKRJxXR+ydgfkF4xUUXeAlaW9gl4j4kyQXYjMza3FqaxGvIakvcArwDeANSrvFpaqZtqarW9JmwC+As0p4/XOBcwG6dOlSwkubmZltGmo7R9wdGA6cTNYlPRJQRBxYYuwKYJeC8c7AuwXjHYFewERJAF8AxkgaFhFTCgNFxJ3AnQADBgwoPm9tZma2yaqtRTwHeAY4OiLmAki6pB6xJwN7SOoGvENW1E+pmhkRi4Htq8YlTQQuLS7CZmZmzVltX186HngfeFLSXZIOovru5mqle1WfD4wDZgMPRcRMSddLGtaQpM3MzJqL2i7WGg2MTj99eCxwCfB5SbcBoyPiL3UFj4ixwNiiadfWsOyQeuRtZmbWLNR5Q4+IWBoR90fEUWTneacDNd6cw8zMzEpXrztrRcQ/I+KOiPh6uRIyMzNrSep9i0szMzNrPC7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnlyIXYzMwsRy7EZmZmOXIhNjMzy5ELsZmZWY7KWoglHSbpVUlzJV1RzfzvS5ol6RVJf5W0aznzMTMza2rKVogltQJuBQ4HegAnS+pRtNjLwICI6A2MAm4sVz5mZmZNUTlbxIOAuRExLyJWAg8CxxQuEBFPRsS/0ugLQOcy5mNmZtbklLMQ7wzMLxivSNNq8i3g/8qYj5mZWZOzeRljq5ppUe2C0mnAAOCAGuafC5wL0KVLl8bKz8zMLHflbBFXALsUjHcG3i1eSNLBwNXAsIhYUV2giLgzIgZExIBOnTqVJVkzM7M8lLMQTwb2kNRNUhtgODCmcAFJewN3kBXhD8uYi5mZWZNUtkIcEZXA+cA4YDbwUETMlHS9pGFpsZ8BHYCHJU2XNKaGcGZmZs1SOc8RExFjgbFF064tGD64nK9vZmbW1PnOWmZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHLkQm5mZ5ciF2MzMLEcuxGZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHLkQm5mZ5ciF2MzMLEcuxGZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHLkQm5mZ5ciF2MzMLEcuxGZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHLkQm5mZ5ciF2MzMLEcuxGZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHLkQm5mZ5ciF2MzMLEcuxGZmZjlyITYzM8uRC7GZmVmOXIjNzMxy5EJsZmaWIxdiMzOzHJW1EEs6TNKrkuZKuqKa+Z+TNDLNf1FS13LmY2Zm1tSUrRBLagXcChwO9ABOltSjaLFvAR9FxO7AL4CflisfMzOzpqicLeJBwNyImBcRK4EHgWOKljkG+G0aHgUcJEllzMnMzKxJKWch3hmYXzBekaZVu0xEVAKLge3KmJOZmVmTsnkZY1fXso0NWAZJ5wLnptElkl5tYG61EmwPLCxKwjEd0zEd0zEdsz52LWWhchbiCmCXgvHOwLs1LFMhaXNgK+CfxYEi4k7gzjLluR5JUyJigGM6pmM6pmM6ZrmVs2t6MrCHpG6S2gDDgTFFy4wBzkzDJwATImK9FrGZmVlzVbYWcURUSjofGAe0Au6JiJmSrgemRMQY4G7g95LmkrWEh5crHzMzs6ZIqG3xAAAKhUlEQVSonF3TRMRYYGzRtGsLhpcDJ5Yzhw1Ujm5wx3RMx3RMx2zeMTeI3BNsZmaWH9/i0szMLEctuhBLOk5SSPpSGu8qaUZjxStHjnnHqSH2FyQ9KOkfkmZJGiupeyPE/bykByTNkzRV0qS0HkMk/akJxVxSNH6WpFvS8HclndEYcRuiMWOVM256j/6+YHxzSQvq2jeS+ko6ooZ5qyVNlzRD0sOS2jf0f72muA2Jl2JeLWmmpFdS7H0aGG+7FGe6pPclvZOGP5Y0q5FjTk8X5jaVmBMlHVo07WJJv6rlOWX5P6lLiy7EwMnAszTeRWI1xlN2y89GjZlTnHWkO6GNBiZGxG4R0QO4Cvh8I8R9FHg6Ir4YEf3Jcu/clGLWJSJuj4jflSt+M7QU6CWpXRo/BHinhOf1BaotxMCyiOgbEb2AlcB3G55m3XGVKfkzVtK+wFFAv4joDRzMujdFqu251V7vExGLUo59gduBX6ThvsBnGxK3ppjpsTI9r17rXkrM+uSYjGD9z7vhaXqT0mILsaQOwH5k97uurnB2lfSMpGnp8ZX6xkutrCclPQD8PU27RtIcSU9IGiHp0nrG3FHS0wVH4l9N05dI+p+U618ldWrMOJJ2lzRe0t/SvN1S+AOBVRFxe9XrRcR04FxJxxTkcL+kYZJ6Snopve4rkvaoYfW/DqwsivtWRNxctI2uK9yGaV26bmhMSZtJer1gvTdT9qMk29cQs1aF+Um6UFmPwSuSHqxHjJr21cmS/p6m1fs+7ZI6SXpE0uT02K845zRe2zYtjtlR0huSWqfxLSW9Kal1Pdb//4Aj0/DJFHxwStpC0j0p35clHZNaTNcDJ6VtdFItsZ8Bdk/DrSTdpawF+peq4i9pN0mPK+sxeUal9SI9A+yePjdmK2t1TQN2qcd+2hFYGBErACJiYUS8K6m/pKdSPuMk7ZjynCjpx5KeAi4qIcdiNa3/BsVNnxEzJN2e1v0aST8rmP89STfWJ0FJP5F0XsH4TyX9u6SD0+fRg8DLNTx9FHCUpM+l53YFdgKmp8+2aWm/FN96eeOLiBb5AE4D7k7DzwP9gK7AjDStPdA2De9B9pWr+sYbQnaE3y1NHwBMB9oBHYHXgUvrGfM/gKvTtFZAxzQcwKlp+FrglsaMA7wIHJeG2wLt0/CFZEevxbkfADyahrcC3iC7Sv/mgvhtgHY1rHu1cdO8IcCf0vB1hdsQmAF0bWDM/wQuTsNDgUfq2Per036terxdsN3W5Ed2Q5vPpeGtS3iPLkl/19tXZB8obwOd0nadABxbV6yiaQ8A+6fhLsDsDdim1cW9tyoXsjvi/U+p6w8sAXqTfYi2TduzcN/8GDitKgbwGrAFcBYF7/katuPmwGPA98j+1yuBvmneQwVx/wrskYb3Ibu/QX3ifgYMTvNK3k9Ah7S+rwG/Ivsfak32P9spLXMS2VdBASYCv6rrfVQQv/C9WNv6lxy3KObuad0HpvGOwD+AzdP4S0CPesbcDZhc8N6fB2xD1luwBOhSR6w/A8ek4SuAn6X9sGWatj0wl7UXLq/3ft4YjxbbIiY70q46Kn8wjRdqDdwl6e/Aw2S/ILUh8V6KiDfS8P7AYxGxLCI+Bf64ATEnA2dLug7YK8WB7B9gZBq+L71Wo8SR1BHYOSJGQ/a1s4j4V22JR8RTZC2EHdLrPRLZ/cQnAVdJuhzYNSKW1bENAJB0a2qNTy5l+QbGvAeoOq/7TbLCUpuqLsqqrrVra1juFeB+SaeRfQiWqrp9NZDsdMCCtF3vB75Wj5iQfZjdImk62c11tkz7uqF+DZydhs9m7fYraf0j4hWyQnEyRV9/JDswuiLlPJGsWHepI592afkpZEXx7jT9jch6bwCmAl2V9R59BXg4PecOspZqfeK+FREvpOGS91NELAH6kx28LCD7P/wO0At4Ir3WD1n3VMrI4jj1sN76N0Lcf0TEZID0Pn0aOFxST2B1RNTrvHRE/AP4VNJeZL/k91JEfJRmT4qIt+sIUdg9XdUtLeDHkl4BxpP95kGDTqU1VFm/R9xUSdqOrJuyl6QgO9IKsqPQKpcAHwB9yLrwl29AvLFkLeI1izZCjj8g+0c+kuxmKD+L6s9BRiPGqS3vmWR3RavO74FTyf4BvgkQEQ9IejG97jhJ346ICTXEPX5NEhHnKesenlK0XCXrnmJpW0eudcaMiPmSPpD0dbIW0am1xKyPI8m2+TCybrue6cO5VhHxtKR19hXwSSPksxmwb/HBkKT6bNP1RMRzqYv2AKBVRFRdFFWf9R8D/JysNVz4QzACjo+Ide43r9ovalqWDpAKlwdYUTBpNVlP1WbAx8XL1zPuBv3PA0TEarIDjImpEXAeMDMi9q3hKUtrmF6K6ta/oXGLn/dr4PvAm9R9QFuTu8l6PLqSHRjV9FrVeRT4X0n9yHrfpkk6i6yHon9ErJL0JvV8jze2ltoiPgH4XUTsGhFdI2IXsq7TwiPNrYD3IuIz4HSyAlbfePsXLfcscLSktunI+8jiQCXE/BrwYUTcRfYG7ZeW34y1BfGU9FqNEiciPiG7H/ixAJI+p7VXiE4APifpnKrEJQ1MH8K/AS4GiIiZad4XgXkRcRPZh23vGtZ/AtBW0vcKplV3VeqbVbmnf7ZuNcSrT0zIPkDuAx5KH44NouzClV0i4kmyg6CtyboiS3nurqy/r14EDpC0vbILAU8GnqpnWn8Bzi94naqi8ialb9Oa/I6s9XFvilPf9b8HuD4i/l40fRxwgVLFk7R3mv4pWVdog6T3+huSTkzxJalPA0KWvJ8k7al1r5noC8wGOim7kAtl59p7NiCfjSoiniPrXj6RDW9lPwIcTbY9xtfz9ZeQHdjcw9prDbYi+39aJelASvxhhnJqqYX4ZLIrfQs9Qna1b5VfAWdKegHoTu1HXzXFO6VwQuqyGQP8DfgDWUtscT1j/obsYoOXyVp3v0zzlgI9JU0lawFf38hxTgcuTN05zwNfSOsUwHHAIcq+vjST7BzPuxHxAdkHSeGR8EnAjNTN9iWyD+z1pLjHkn2IvSHpJbLfrr68mnXZNsX7Htn5tWrVIyZk+6kDG34UX6wVcF9q5bxMdq764xKfO4SifRUR7wFXAk+SvZ+mRcRjtcRoL6mi4PF9snPmA5RdPDWLtVf9lrxNa4gLWRfsNqz98KvX+kdERUT8sppZN5CdNnpF2dePbkjTnwR6qO6LtUpxKvAtSX8j60XZ4It56rmfOgC/Vbqgjex02LVkB8Y/TflMJ+s635SMIvumQk2fdbWK7A6MTwMjUsOovkaQ9WxWnZ67n+x9P4VsX8/ZkLwak++stZFJ6hARS1KL8mng3IiY1ghxl0RESS2sjREnxWpPdrV4vw39J8yLpAFkxeKreeeyKZJ0AtlFMqfnnYvlS9LjwE/SdSMb8vzNyA5Ajo2IeY2aXBPRUlvEeboztTSmkV3A1OAi3BRJOpjsSPPmTbAIX0HWKrwy71w2RZJuBv4fa1ur1gIpu0nHa8BHDSjCe5Fdef14cy3C4BaxmZlZrtwiNjMzy5ELsZmZWY5ciM3MzHLkQmxmZpYjF2IzM7McuRCbmZnl6P8DKkFuvBSfv/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.arange(len(baseline_auc_scores))\n",
    "labels = [amino_acid[:3] for amino_acid in list(baseline_aucs.keys())]\n",
    "labels[3] = \"Aspc\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.subplots_adjust(left=0.01, bottom=0.07, right=1.0, top=1.0, wspace=0.2 , hspace=0.17)\n",
    "width = 0.25\n",
    "rects1 = ax.bar(ind, baseline_auc_scores, width, color = 'b')\n",
    "rects2 = ax.bar(ind + width , average_auc_scores, width, color = 'r')\n",
    "\n",
    "ax.set_ylabel('AUC Scores')\n",
    "ax.set_title('NIST Baseline AUC vs Average AUC')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('Baseline', 'Average'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

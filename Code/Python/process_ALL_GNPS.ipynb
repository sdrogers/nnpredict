{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"G:\\\\Dev\\\\Data\"\n",
    "\n",
    "all_gnps_path = datapath + os.sep + \"ALL_GNPS_20181012.mgf\"\n",
    "all_gnps_filtered_path = datapath + os.sep + \"ALL_GNPS_20181012_filtered.mgf\"\n",
    "all_gnps_processed_path = datapath + os.sep + \"ALL_GNPS_20181012_processed.mgf\"\n",
    "\n",
    "mibig_gnps_linked_file_path = datapath + os.sep + \"mibig_gnps_links_q3_loose.csv\"\n",
    "\n",
    "gnps_dir = datapath + os.sep + \"GNPS For Family\"\n",
    "gnps_5770_dir = datapath + os.sep + \"GNPS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert .mgf to individual .ms file\n",
    "Sample .ms file as follows: \n",
    "\n",
    "-  compound Kanamycin A M+H\n",
    "-  formula C18H36N4O11\n",
    "-  parentmass 485.0\n",
    "-  ionization [M + H]+\n",
    "-  InChI InChI=1S/C18H36N4O11/c19-2-6-10(25)12(27)13(28)18(30-6)33-16-5(21)1-4(20)15(14(16)29)32-17-11(26)8(22)9(24)7(3-23)31-17/h4-18,23-29H,1-3,19-22H2/t4-,5+,6-,7-,8+,9-,10-,11-,12+,13-,14-,15+,16-,17-,18-/m1/s1\n",
    "-  InChIKey N/A\n",
    "-  smiles O\n",
    "\n",
    "-  ms2peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnps_5770_filenames = []\n",
    "\n",
    "for file in os.listdir(gnps_5770_datapath):\n",
    "    gnps_5770_filenames.append(file[:-3])\n",
    "\n",
    "with open(all_gnps_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    if line.startswith(\"SPECTRUMID=\") and line[11:-1] not in gnps_5770_filenames:\n",
    "        filename = line[11:-1]\n",
    "        print(line[11:-1])\n",
    "        filepath = os.path.join(datapath, filename + \".ms\")\n",
    "        spectrum_id_index = content.index(line)\n",
    "        loop_index = spectrum_id_index + 2\n",
    "        smiles_index = spectrum_id_index - 6\n",
    "        if content[loop_index] != \"END IONS\\n\" and content[smiles_index][7:-1] != \"N/A\" and \\\n",
    "                content[smiles_index][7:-1] != \"\" and content[smiles_index][7:-1] != \" \":\n",
    "\n",
    "            with open(filepath, 'w') as f:\n",
    "                inchi_index = spectrum_id_index - 5\n",
    "                smiles_index = inchi_index - 1\n",
    "                name_index = smiles_index - 3\n",
    "                ionmode_index = name_index - 2\n",
    "                pepmass_index = ionmode_index - 6\n",
    "\n",
    "                f.write(\">compound \" + content[name_index][5:])\n",
    "                if content[inchi_index][7:].startswith(\"InChI\"):\n",
    "                    f.write(\">formula \" + content[inchi_index][7:].split(\"/\")[1] + \"\\n\")\n",
    "                else:\n",
    "                    f.write(\">formula N/A\\n\")\n",
    "                f.write(\">parentmass \" + content[pepmass_index][8:])\n",
    "                f.write(\">ionization \" + content[ionmode_index][8:])\n",
    "                f.write(\">InChI \" + content[inchi_index][7:-2] + \"\\n\")\n",
    "                f.write(\">InChIKey N/A\\n\")\n",
    "                if content[smiles_index][7:].startswith(\" \"):# there are some smiles with additional space at start\n",
    "                    f.write(\">smiles \" + content[smiles_index][8:])\n",
    "                else:\n",
    "                    f.write(\">smiles \" + content[smiles_index][7:])\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\">ms2peaks\\n\")\n",
    "                while content[loop_index] != \"END IONS\\n\":\n",
    "                    mass, intensity = content[loop_index].split(\"\\t\")\n",
    "                    f.write(mass + \" \" + intensity)\n",
    "                    loop_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only the ones that are linked with Mibig (350 of them). These samples will be run with CSI:FingerID Sirius tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnps_ids = set()\n",
    "to_be_deleted = []\n",
    "\n",
    "mibig_gnps_df = pd.read_csv(mibig_gnps_linked_file_path, sep=\",\")\n",
    "mibig_gnps_df = mibig_gnps_df.set_index(\"gnps_id\")\n",
    "\n",
    "with open(all_gnps_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for index, line in enumerate(content):\n",
    "    if line.startswith(\"SPECTRUMID=\"):\n",
    "        spectrum_id = line.split(\"=\")[1][:-1]\n",
    "        starting_index = index - 18\n",
    "        loop_index = index + 2\n",
    "\n",
    "        while not content[starting_index].startswith(\"BEGIN IONS\"):\n",
    "            starting_index -= 1\n",
    "\n",
    "        while content[loop_index] != \"END IONS\\n\":\n",
    "            loop_index += 1\n",
    "\n",
    "        if spectrum_id not in mibig_gnps_df.index:\n",
    "            to_be_deleted.append((starting_index, loop_index + 1))\n",
    "\n",
    "\n",
    "for start, end in to_be_deleted:\n",
    "    while start <= end:\n",
    "        content[start] = \"TO BE DELETED\\n\"\n",
    "        start += 1\n",
    "\n",
    "filtered_content = [line for line in content if line != \"TO BE DELETED\\n\"]\n",
    "\n",
    "with open(all_gnps_filtered_path, 'w') as f:\n",
    "    for line in filtered_content:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter noises out from those 350 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_deleted = []\n",
    "\n",
    "with open(all_gnps_filtered_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "def filter_and_normalise(content, peak_intensities):\n",
    "    max = 0\n",
    "\n",
    "    for index, peak, intensity in peak_intensities:\n",
    "        if peak > 1000:\n",
    "            content[index] = \"TO BE DELETED\\n\"\n",
    "        else:\n",
    "            if intensity > max:\n",
    "                max = intensity\n",
    "\n",
    "    for index, peak, intensity in peak_intensities:\n",
    "        if intensity < max * 0.005:\n",
    "            content[index] = \"TO BE DELETED\\n\"\n",
    "\n",
    "for index, line in enumerate(content):\n",
    "    if line.startswith(\"CHARGE=\"):\n",
    "        peak_intensities = []\n",
    "        charge_index = index\n",
    "        cursor_index = index\n",
    "        pep_mass_index = index - 1\n",
    "\n",
    "        starting_index = pep_mass_index - 1\n",
    "\n",
    "        while not content[starting_index].startswith(\"BEGIN IONS\"):\n",
    "            starting_index -= 1\n",
    "\n",
    "        charge = int(content[charge_index][:-1].split(\"=\")[1])\n",
    "        pep_mass = float(content[pep_mass_index][:-1].split(\"=\")[1])\n",
    "\n",
    "        if charge == 0:\n",
    "            content[charge_index] = \"CHARGE=1\\n\"\n",
    "        elif charge > 1:\n",
    "            print(\"check\")\n",
    "            content[pep_mass_index] = str((pep_mass * charge) - charge + 1) + \"\\n\"\n",
    "            content[charge_index] = \"CHARGE=1\\n\"\n",
    "\n",
    "        while not content[cursor_index].startswith(\"SCANS\"):\n",
    "            cursor_index += 1\n",
    "\n",
    "        spectrum_id_index = cursor_index - 1\n",
    "        spectrum_id = content[spectrum_id_index][:-1].split(\"=\")[1]\n",
    "\n",
    "        loop_index = cursor_index + 1\n",
    "\n",
    "        cursor_index = index\n",
    "\n",
    "        while not content[cursor_index].startswith(\"NAME\"):\n",
    "            cursor_index += 1\n",
    "\n",
    "        content[cursor_index] = \"NAME=\" + spectrum_id + \"\\n\"\n",
    "\n",
    "        while content[loop_index] != \"END IONS\\n\":\n",
    "            peak, intensity = content[loop_index][:-1].split(\"\\t\")\n",
    "            peak_intensities.append((loop_index, float(peak), float(intensity)))\n",
    "            loop_index += 1\n",
    "\n",
    "        filter_and_normalise(content, peak_intensities)\n",
    "\n",
    "filtered_content = [line for line in content if line != \"TO BE DELETED\\n\"]\n",
    "print(len(filtered_content))\n",
    "\n",
    "with open(all_gnps_processed_path, 'w') as f:\n",
    "    for line in filtered_content:\n",
    "        f.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
